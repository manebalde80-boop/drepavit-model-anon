{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import torch.cuda.amp as amp\n",
    "import random\n",
    "from torchvision.utils import make_grid\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TRAIN_DIR = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/train'\n",
    "    VAL_DIR   = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/val'\n",
    "    TEST_DIR  = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/test'\n",
    "\n",
    "    IMG_SIZE = 224\n",
    "    NUM_CLASSES = 3\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_EPOCHS = 100\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=self.alpha)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = -self.ce(inputs, targets)\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = ((1 - pt) ** self.gamma) * -logpt\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(Config.IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(Config.TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(Config.VAL_DIR, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(Config.TEST_DIR, transform=val_test_transforms)\n",
    "\n",
    "class_counts = torch.bincount(torch.tensor([label for _, label in train_dataset]))\n",
    "class_weights = (1. / class_counts.float()).to(Config.DEVICE)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, sampler=sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Visualisation et Division des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_folder(folder):\n",
    "    total = 0\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            total += len(os.listdir(label_folder))\n",
    "    return total\n",
    "\n",
    "train_count = count_images_in_folder(Config.TRAIN_DIR)\n",
    "val_count = count_images_in_folder(Config.VAL_DIR)\n",
    "test_count = count_images_in_folder(Config.TEST_DIR)\n",
    "\n",
    "print(f\"Number of images:\")\n",
    "print(f\" - Training: {train_count}\")\n",
    "print(f\" - Validation: {val_count}\")\n",
    "print(f\" - Test: {test_count}\")\n",
    "\n",
    "def visualize_batch(dataloader, title, class_names):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:8]\n",
    "    labels = labels[:8]\n",
    "\n",
    "    inv_norm = transforms.Normalize(\n",
    "        mean=[-m/s for m, s in zip([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])],\n",
    "        std=[1/s for s in [0.229, 0.224, 0.225]]\n",
    "    )\n",
    "    images = torch.stack([inv_norm(img) for img in images])\n",
    "\n",
    "    grid = make_grid(images, nrow=4)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title(title + \" | \" + \", \".join([class_names[label] for label in labels]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "visualize_batch(train_loader, \"Training Images\", class_names)\n",
    "visualize_batch(val_loader, \"Validation Images\", class_names)\n",
    "visualize_batch(test_loader, \"Test Images\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_heads = config.NUM_HEADS\n",
    "        self.head_dim = config.HIDDEN_DIM // config.NUM_HEADS\n",
    "\n",
    "        self.qkv = nn.Linear(config.HIDDEN_DIM, 3 * config.HIDDEN_DIM)\n",
    "        self.proj = nn.Linear(config.HIDDEN_DIM, config.HIDDEN_DIM)\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.head_dim**-0.5\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc MLP\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.HIDDEN_DIM, config.MLP_DIM)\n",
    "        self.fc2 = nn.Linear(config.MLP_DIM, config.HIDDEN_DIM)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Module TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc Transformer\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.attn = MultiHeadAttention(config)\n",
    "        self.norm2 = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.mlp = MLPBlock(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Module HybridModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Branche CNN\n",
    "        self.cnn = timm.create_model(\n",
    "            config.CNN_BACKBONE,\n",
    "            pretrained=True,\n",
    "            features_only=True,\n",
    "            out_indices=[4]\n",
    "        )\n",
    "\n",
    "        # Projection CNN\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, config.IMG_SIZE, config.IMG_SIZE)\n",
    "            cnn_feat = self.cnn(dummy)[0]\n",
    "            self.cnn_feat_dim = cnn_feat.shape[1]\n",
    "\n",
    "        self.cnn_proj = nn.Sequential(\n",
    "            nn.Conv2d(self.cnn_feat_dim, config.HIDDEN_DIM, 1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Branche Transformer\n",
    "        self.patch_embed = nn.Conv2d(\n",
    "            config.NUM_CHANNELS,\n",
    "            config.HIDDEN_DIM,\n",
    "            kernel_size=config.PATCH_SIZE,\n",
    "            stride=config.PATCH_SIZE\n",
    "        )\n",
    "\n",
    "        num_patches = (config.IMG_SIZE // config.PATCH_SIZE) ** 2\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, config.HIDDEN_DIM))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config.HIDDEN_DIM))\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(config) for _ in range(config.NUM_LAYERS)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.head = nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraction des caracteristique des CNN\n",
    "        cnn_features = self.cnn_proj(self.cnn(x)[0])\n",
    "\n",
    "        # Passage au Transformer\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = x[:, 0]\n",
    "\n",
    "        # Fusion Tranformer + CNN\n",
    "        x = self.norm(x + cnn_features)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Initialisation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.CNN_BACKBONE = 'resnet50'\n",
    "Config.HIDDEN_DIM = 256\n",
    "Config.MLP_DIM = 512\n",
    "Config.NUM_HEADS = 4\n",
    "Config.NUM_LAYERS = 4\n",
    "Config.DROPOUT = 0.1\n",
    "Config.NUM_CHANNELS = 3\n",
    "Config.PATCH_SIZE = 16\n",
    "\n",
    "model = HybridModel(Config).to(Config.DEVICE)\n",
    "\n",
    "criterion = FocalLoss(alpha=class_weights, gamma=2.0).to(Config.DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "scaler = amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from thop import profile\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "summary(model, input_size=(1, 3, Config.IMG_SIZE, Config.IMG_SIZE), device=device_str)\n",
    "\n",
    "model.eval()\n",
    "dummy = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE, device=Config.DEVICE)\n",
    "with torch.no_grad():\n",
    "    flops, params = profile(model, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(f\"\\nParamètres: {params/1e6:.2f} M\")\n",
    "print(f\"FLOPs (forward, bs=1): {flops/1e9:.2f} GFLOPs\")\n",
    "print(f\"FLOPs par batch (bs={Config.BATCH_SIZE}): {(flops*Config.BATCH_SIZE)/1e9:.2f} GFLOPs\")\n",
    "print(\"Note: l'entraînement (forward+backward) ≈ 2–3× ces FLOPs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(loader), 100. * correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "for epoch in range(Config.NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{Config.NUM_EPOCHS} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "epochs = range(1, Config.NUM_EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation sur les données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonne\n",
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def full_evaluation(model, loader, criterion, name=\"\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = np.mean(np.diag(cm) / np.maximum(1, np.sum(cm, axis=1)))\n",
    "    specificity = np.mean([\n",
    "        (np.sum(cm) - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])) /\n",
    "        max(1, (np.sum(cm) - cm[:, i].sum()))\n",
    "        for i in range(len(cm))\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        one_hot_labels = label_binarize(all_labels, classes=np.unique(all_labels))\n",
    "        auc = roc_auc_score(one_hot_labels, all_probs, average='macro', multi_class='ovo')\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur AUC ({name}) :\", e)\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\n Évaluation sur {name} :\")\n",
    "    print(f\"Loss        : {total_loss / len(loader):.4f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"F1-Score    : {f1:.4f}\")\n",
    "    print(f\"Sensitivity : {sensitivity:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")\n",
    "\n",
    "    target_names = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "    print(\"\\n Rapport de classification :\\n\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, train_loader, criterion, name=\"Train\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"hybrid_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y_true = []\n",
    "y_pred_proba = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(Config.DEVICE)\n",
    "        labels = labels.to(Config.DEVICE)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred_proba.extend(probs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "n_classes = y_pred_proba.shape[1]\n",
    "\n",
    "y_test_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['#1f77b4', '#d62728', '#2ca02c'])\n",
    "target_names = ['Normal', 'Sickle', 'Other']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{target_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         color='gray', linestyle='--', linewidth=2.5,\n",
    "         label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curves per Class with Micro-Average', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "TARGET_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "\n",
    "def plot_pr_curve(model, loader, name=\"Test\"):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    classes = np.unique(all_labels)\n",
    "    y_true = label_binarize(all_labels, classes=classes)\n",
    "    n_classes = y_true.shape[1]\n",
    "\n",
    "    if len(TARGET_NAMES) == n_classes:\n",
    "        class_names = TARGET_NAMES\n",
    "    else:\n",
    "        class_names = [f\"Classe {c}\" for c in classes]\n",
    "\n",
    "    ap_per_class = []\n",
    "    plt.figure(figsize=(7,6))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_true[:, i], all_probs[:, i])\n",
    "        ap = average_precision_score(y_true[:, i], all_probs[:, i])\n",
    "        ap_per_class.append(ap)\n",
    "        plt.plot(recall, precision, lw=2, label=f\"{class_names[i]} (AP = {ap:.3f})\")\n",
    "\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(y_true.ravel(), all_probs.ravel())\n",
    "    ap_micro = average_precision_score(y_true, all_probs, average=\"micro\")\n",
    "    plt.plot(recall_micro, precision_micro, linestyle=\"--\", lw=2,\n",
    "             label=f\"Micro-average (AP = {ap_micro:.3f})\")\n",
    "\n",
    "    ap_macro = float(np.mean(ap_per_class))\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision–Recall Curve - {name} (macro AP = {ap_macro:.3f})\")\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_curve(model, test_loader, name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        self.fwd_hook = target_layer.register_forward_hook(self._save_activations)\n",
    "        self.bwd_hook = target_layer.register_full_backward_hook(self._save_gradients)\n",
    "\n",
    "    def _save_activations(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _save_gradients(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        self.fwd_hook.remove()\n",
    "        self.bwd_hook.remove()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _normalize(self, cam):\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "    def __call__(self, images, targets=None, device=None):\n",
    "\n",
    "        device = device or next(self.model.parameters()).device\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = self.model(images)  \n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        if targets is None:\n",
    "            targets = preds\n",
    "        else:\n",
    "            targets = torch.as_tensor(targets, device=device)\n",
    "\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        selected = outputs.gather(1, targets.view(-1,1)).sum()\n",
    "        selected.backward()\n",
    "\n",
    "        A = self.activations           \n",
    "        dA = self.gradients            \n",
    "        B, C, H, W = A.shape\n",
    "\n",
    "        weights = dA.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)  \n",
    "        cam = (weights * A).sum(dim=1)                           \n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        heatmaps = torch.stack([self._normalize(cam[i]) for i in range(B)], dim=0)  # (B,H,W)\n",
    "        return heatmaps.cpu(), preds.cpu(), probs.detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam(images, heatmaps, true_labels=None, pred_labels=None, class_names=None, cols=4):\n",
    " images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  \n",
    "        imgs = imgs.repeat(1,3,1,1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(4*cols, 4*rows))\n",
    "\n",
    "    for i in range(B):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = np.transpose(imgs[i].numpy(), (1,2,0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')  \n",
    "        title = \"\"\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title += f\"Pred: {class_names[int(pred_labels[i])]}\"\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title += f\"\\nTrue: {class_names[int(true_labels[i])]}\"\n",
    "        plt.title(title.strip(), fontsize=10)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam_with_original(images, heatmaps, true_labels=None, pred_labels=None,\n",
    "                               class_names=None, scores=None, score_name=\"p\", cols=4):\n",
    "\n",
    "    imgs = images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  \n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(8*cols, 4*rows))  \n",
    "\n",
    "    for i in range(B):\n",
    "        img = np.transpose(imgs[i].numpy(), (1, 2, 0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        plt.subplot(rows, cols*2, 2*i+1)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        title_parts = []\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(rows, cols*2, 2*i+2)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')\n",
    "\n",
    "        title_parts = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_parts.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]  \n",
    "device = Config.DEVICE\n",
    "\n",
    "target_layer = model.cnn.layer4[-1]   \n",
    "\n",
    "cam = GradCAM(model.to(device).eval(), target_layer=target_layer)\n",
    "\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images = batch_images.to(device)\n",
    "batch_labels = batch_labels.to(device)\n",
    "\n",
    "heatmaps, preds, probs = cam(batch_images, targets=batch_labels, device=device)\n",
    "\n",
    "show_gradcam(batch_images, heatmaps, true_labels=batch_labels.cpu(),\n",
    "             pred_labels=preds, class_names=CLASS_NAMES, cols=4)\n",
    "\n",
    "cam.remove_hooks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
