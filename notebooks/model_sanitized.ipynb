{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import torch.cuda.amp as amp\n",
    "import random\n",
    "from torchvision.utils import make_grid\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TRAIN_DIR = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/train'\n",
    "    VAL_DIR   = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/val'\n",
    "    TEST_DIR  = '/content/drive/MyDrive/Drepa_Vite/Dataset_drépano/test'\n",
    "\n",
    "    IMG_SIZE = 224\n",
    "    NUM_CLASSES = 3\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_EPOCHS = 100\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=self.alpha)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = -self.ce(inputs, targets)\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = ((1 - pt) ** self.gamma) * -logpt\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(Config.IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(Config.TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(Config.VAL_DIR, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(Config.TEST_DIR, transform=val_test_transforms)\n",
    "\n",
    "class_counts = torch.bincount(torch.tensor([label for _, label in train_dataset]))\n",
    "class_weights = (1. / class_counts.float()).to(Config.DEVICE)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, sampler=sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Visualisation et Division des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_folder(folder):\n",
    "    total = 0\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            total += len(os.listdir(label_folder))\n",
    "    return total\n",
    "\n",
    "train_count = count_images_in_folder(Config.TRAIN_DIR)\n",
    "val_count = count_images_in_folder(Config.VAL_DIR)\n",
    "test_count = count_images_in_folder(Config.TEST_DIR)\n",
    "\n",
    "print(f\"Number of images:\")\n",
    "print(f\" - Training: {train_count}\")\n",
    "print(f\" - Validation: {val_count}\")\n",
    "print(f\" - Test: {test_count}\")\n",
    "\n",
    "def visualize_batch(dataloader, title, class_names):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images = images[:8]\n",
    "    labels = labels[:8]\n",
    "\n",
    "    inv_norm = transforms.Normalize(\n",
    "        mean=[-m/s for m, s in zip([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])],\n",
    "        std=[1/s for s in [0.229, 0.224, 0.225]]\n",
    "    )\n",
    "    images = torch.stack([inv_norm(img) for img in images])\n",
    "\n",
    "    grid = make_grid(images, nrow=4)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title(title + \" | \" + \", \".join([class_names[label] for label in labels]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "visualize_batch(train_loader, \"Training Images\", class_names)\n",
    "visualize_batch(val_loader, \"Validation Images\", class_names)\n",
    "visualize_batch(test_loader, \"Test Images\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(test_dataset) - 1)\n",
    "image_tensor, label = test_dataset[idx]\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "image_tensor_denorm = image_tensor * std + mean\n",
    "image_np = image_tensor_denorm.permute(1, 2, 0).numpy()\n",
    "\n",
    "patch_size = 16\n",
    "patches = []\n",
    "\n",
    "for i in range(0, image_np.shape[0], patch_size):\n",
    "    for j in range(0, image_np.shape[1], patch_size):\n",
    "        patch = image_np[i:i+patch_size, j:j+patch_size, :]\n",
    "        patches.append(patch)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.title(\"Selected Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "num_patches_per_row = image_np.shape[0] // patch_size\n",
    "fig_patches, axs = plt.subplots(num_patches_per_row, num_patches_per_row, figsize=(6, 6))\n",
    "\n",
    "for idx, patch in enumerate(patches):\n",
    "    row = idx // num_patches_per_row\n",
    "    col = idx % num_patches_per_row\n",
    "    axs[row, col].imshow(patch)\n",
    "    axs[row, col].axis(\"off\")\n",
    "\n",
    "fig_patches.suptitle(\"Extracted Patches (Vision Transformer\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creation de l'Architecture du Modèle (DrepaViT - CNN + Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Module MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_heads = config.NUM_HEADS\n",
    "        self.head_dim = config.HIDDEN_DIM // config.NUM_HEADS\n",
    "\n",
    "        self.qkv = nn.Linear(config.HIDDEN_DIM, 3 * config.HIDDEN_DIM)\n",
    "        self.proj = nn.Linear(config.HIDDEN_DIM, config.HIDDEN_DIM)\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.head_dim**-0.5\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Module MLPBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc MLP\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.HIDDEN_DIM, config.MLP_DIM)\n",
    "        self.fc2 = nn.Linear(config.MLP_DIM, config.HIDDEN_DIM)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Module TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloc Transformer\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.attn = MultiHeadAttention(config)\n",
    "        self.norm2 = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.mlp = MLPBlock(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Module HybridModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Branche CNN\n",
    "        self.cnn = timm.create_model(\n",
    "            config.CNN_BACKBONE,\n",
    "            pretrained=True,\n",
    "            features_only=True,\n",
    "            out_indices=[4]\n",
    "        )\n",
    "\n",
    "        # Projection CNN\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, config.IMG_SIZE, config.IMG_SIZE)\n",
    "            cnn_feat = self.cnn(dummy)[0]\n",
    "            self.cnn_feat_dim = cnn_feat.shape[1]\n",
    "\n",
    "        self.cnn_proj = nn.Sequential(\n",
    "            nn.Conv2d(self.cnn_feat_dim, config.HIDDEN_DIM, 1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Branche Transformer\n",
    "        self.patch_embed = nn.Conv2d(\n",
    "            config.NUM_CHANNELS,\n",
    "            config.HIDDEN_DIM,\n",
    "            kernel_size=config.PATCH_SIZE,\n",
    "            stride=config.PATCH_SIZE\n",
    "        )\n",
    "\n",
    "        num_patches = (config.IMG_SIZE // config.PATCH_SIZE) ** 2\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, config.HIDDEN_DIM))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config.HIDDEN_DIM))\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(config) for _ in range(config.NUM_LAYERS)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(config.HIDDEN_DIM)\n",
    "        self.head = nn.Linear(config.HIDDEN_DIM, config.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraction des caracteristique des CNN\n",
    "        cnn_features = self.cnn_proj(self.cnn(x)[0])\n",
    "\n",
    "        # Passage au Transformer\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = x[:, 0]\n",
    "\n",
    "        # Fusion Tranformer + CNN\n",
    "        x = self.norm(x + cnn_features)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Initialisation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.CNN_BACKBONE = 'resnet50'\n",
    "Config.HIDDEN_DIM = 256\n",
    "Config.MLP_DIM = 512\n",
    "Config.NUM_HEADS = 4\n",
    "Config.NUM_LAYERS = 4\n",
    "Config.DROPOUT = 0.1\n",
    "Config.NUM_CHANNELS = 3\n",
    "Config.PATCH_SIZE = 16\n",
    "\n",
    "model = HybridModel(Config).to(Config.DEVICE)\n",
    "\n",
    "criterion = FocalLoss(alpha=class_weights, gamma=2.0).to(Config.DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)\n",
    "scaler = amp.GradScaler()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMÈTRES DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Résumé & FLOPs (⚠️ remplace Cfg par Config) ---\n",
    "from torchinfo import summary\n",
    "from thop import profile\n",
    "\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "summary(model, input_size=(1, 3, Config.IMG_SIZE, Config.IMG_SIZE), device=device_str)\n",
    "\n",
    "model.eval()\n",
    "dummy = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE, device=Config.DEVICE)\n",
    "with torch.no_grad():\n",
    "    flops, params = profile(model, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(f\"\\nParamètres: {params/1e6:.2f} M\")\n",
    "print(f\"FLOPs (forward, bs=1): {flops/1e9:.2f} GFLOPs\")\n",
    "print(f\"FLOPs par batch (bs={Config.BATCH_SIZE}): {(flops*Config.BATCH_SIZE)/1e9:.2f} GFLOPs\")\n",
    "print(\"Note: l'entraînement (forward+backward) ≈ 2–3× ces FLOPs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        with amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(loader), 100. * correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "for epoch in range(Config.NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{Config.NUM_EPOCHS} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "epochs = range(1, Config.NUM_EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EVALUATION DU MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. EVALUATION GLOBALE DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def full_evaluation(model, loader, criterion, name=\"\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = np.mean(np.diag(cm) / np.maximum(1, np.sum(cm, axis=1)))  # Rappel moyen\n",
    "    specificity = np.mean([\n",
    "        (np.sum(cm) - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])) /\n",
    "        max(1, (np.sum(cm) - cm[:, i].sum()))\n",
    "        for i in range(len(cm))\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        one_hot_labels = label_binarize(all_labels, classes=np.unique(all_labels))\n",
    "        auc = roc_auc_score(one_hot_labels, all_probs, average='macro', multi_class='ovo')\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur AUC ({name}) :\", e)\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\n Évaluation sur {name} :\")\n",
    "    print(f\"Loss        : {total_loss / len(loader):.4f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"F1-Score    : {f1:.4f}\")\n",
    "    print(f\"Sensitivity : {sensitivity:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation sur les données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonne\n",
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation sur les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonne\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonne\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de confusion sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def full_evaluation(model, loader, criterion, name=\"\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = np.mean(np.diag(cm) / np.maximum(1, np.sum(cm, axis=1)))\n",
    "    specificity = np.mean([\n",
    "        (np.sum(cm) - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])) /\n",
    "        max(1, (np.sum(cm) - cm[:, i].sum()))\n",
    "        for i in range(len(cm))\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        one_hot_labels = label_binarize(all_labels, classes=np.unique(all_labels))\n",
    "        auc = roc_auc_score(one_hot_labels, all_probs, average='macro', multi_class='ovo')\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur AUC ({name}) :\", e)\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"\\n Évaluation sur {name} :\")\n",
    "    print(f\"Loss        : {total_loss / len(loader):.4f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"F1-Score    : {f1:.4f}\")\n",
    "    print(f\"Sensitivity : {sensitivity:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")\n",
    "\n",
    "    target_names = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "    print(\"\\n Rapport de classification :\\n\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, train_loader, criterion, name=\"Entraînement\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def full_evaluation(model, loader, criterion, name=\"\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # --- Metrics ---\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = np.mean(np.diag(cm) / np.maximum(1, np.sum(cm, axis=1)))\n",
    "    specificity = np.mean([\n",
    "        (np.sum(cm) - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])) /\n",
    "        max(1, (np.sum(cm) - cm[:, i].sum()))\n",
    "        for i in range(len(cm))\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        one_hot_labels = label_binarize(all_labels, classes=np.unique(all_labels))\n",
    "        auc = roc_auc_score(one_hot_labels, all_probs, average='macro', multi_class='ovo')\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur AUC ({name}) :\", e)\n",
    "        auc = float('nan')\n",
    "\n",
    "    # --- Print results ---\n",
    "    print(f\"\\n Évaluation sur {name} :\")\n",
    "    print(f\"Loss        : {total_loss / len(loader):.4f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"F1-Score    : {f1:.4f}\")\n",
    "    print(f\"Sensitivity : {sensitivity:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")\n",
    "\n",
    "    target_names = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "    print(\"\\n Rapport de classification :\\n\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=2))\n",
    "\n",
    "    # --- Matrice de confusion ---\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel(\"Prédictions\")\n",
    "    plt.ylabel(\"Vérités\")\n",
    "    plt.title(f\"Matrice de confusion - {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def full_evaluation(model, loader, criterion, name=\"\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # --- Metrics ---\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sensitivity = np.mean(np.diag(cm) / np.maximum(1, np.sum(cm, axis=1)))\n",
    "    specificity = np.mean([\n",
    "        (np.sum(cm) - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])) /\n",
    "        max(1, (np.sum(cm) - cm[:, i].sum()))\n",
    "        for i in range(len(cm))\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        one_hot_labels = label_binarize(all_labels, classes=np.unique(all_labels))\n",
    "        auc = roc_auc_score(one_hot_labels, all_probs, average='macro', multi_class='ovo')\n",
    "    except Exception as e:\n",
    "        print(f\" AUC Error ({name}) :\", e)\n",
    "        auc = float('nan')\n",
    "\n",
    "    # --- Print results ---\n",
    "    print(f\"\\n Evaluation on {name} :\")\n",
    "    print(f\"Loss        : {total_loss / len(loader):.4f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {precision:.4f}\")\n",
    "    print(f\"Recall      : {recall:.4f}\")\n",
    "    print(f\"F1-Score    : {f1:.4f}\")\n",
    "    print(f\"Sensitivity : {sensitivity:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")\n",
    "\n",
    "    target_names = [\"Others\", \"Sickle Cells\", \"Normals\"]\n",
    "    print(\"\\n Classification report :\\n\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=2))\n",
    "\n",
    "    # --- Confusion matrix ---\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonne\n",
    "full_evaluation(model, train_loader, criterion, name=\"Train\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonne\n",
    "full_evaluation(model, train_loader, criterion, name=\"Train\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation(model, train_loader, criterion, name=\"Train\")\n",
    "full_evaluation(model, val_loader, criterion, name=\"Validation\")\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation sur le jeu de test\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Enregistrement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sauvegarde (après entraînement)\n",
    "torch.save(model.state_dict(), \"hybrid_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"model_complet.pth\")\n",
    "#torch.save(model, \"00model_complet.pth\")\n",
    "torch.save(model, \"0model_complet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rechargement (plus tard / dans un autre script)\n",
    "model = HybridModel(Config)\n",
    "model.load_state_dict(torch.load(\"hybrid_model_weights.pth\", map_location=Config.DEVICE))\n",
    "model.to(Config.DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Charger le meilleur modèle =====\n",
    "ckpt_path = \"hybrid_model_weights.pth\"   # ajuste si ton meilleur fichier a un autre nom\n",
    "model = HybridModel(Config)\n",
    "state = torch.load(ckpt_path, map_location=Config.DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.to(Config.DEVICE)\n",
    "model.eval()\n",
    "print(f\"✅ Modèle chargé depuis: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÉVALUATION SUR LE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2) Évaluer sur le jeu de TEST =====\n",
    "# Si tu utilises la version qui affiche la matrice (avec seaborn), appelle:\n",
    "full_evaluation(model, test_loader, criterion, name=\"Test\")\n",
    "\n",
    "# OU, si tu utilises la version qui renvoie les métriques + cm :\n",
    "# metrics_test, cm_test = full_evaluation_return(model, test_loader, criterion, name=\"Test\")\n",
    "\n",
    "# ===== 3) (Optionnel) Sauvegarder métriques + matrice de confusion =====\n",
    "# Décommente si tu as les helpers save_confusion_matrix / save_metrics\n",
    "# import os\n",
    "# os.makedirs(\"eval_test_outputs\", exist_ok=True)\n",
    "# save_confusion_matrix(cm_test, [\"Autres\",\"Falciformes\",\"Normales\"],\n",
    "#                       out_path=\"eval_test_outputs/confusion_matrix_test.png\",\n",
    "#                       title=\"Matrice de confusion - Test\")\n",
    "# save_metrics(metrics_test, out_json=\"eval_test_outputs/metrics_test.json\",\n",
    "#              out_csv=\"eval_test_outputs/metrics_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La courbe ROC du test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y_true = []\n",
    "y_pred_proba = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(Config.DEVICE)\n",
    "        labels = labels.to(Config.DEVICE)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred_proba.extend(probs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "n_classes = y_pred_proba.shape[1]\n",
    "\n",
    "# One-hot encode labels\n",
    "y_test_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "# ROC per class\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# --- Micro-average ---\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['#1f77b4', '#d62728', '#2ca02c'])\n",
    "target_names = ['Normal', 'Sickle', 'Other']\n",
    "\n",
    "# Plot per class\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{target_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot micro-average (gray, dashed)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         color='gray', linestyle='--', linewidth=2.5,\n",
    "         label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.2f})')\n",
    "\n",
    "# Diagonal line (random chance)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curves per Class with Micro-Average', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "n_classes = y_pred_proba.shape[1]\n",
    "\n",
    "# One-hot encode labels\n",
    "y_test_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['#1f77b4', '#d62728', '#2ca02c'])\n",
    "target_names = ['Normal', 'Sickle', 'Other']\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{target_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Diagonal line (random chance)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curves per Class', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "n_classes = y_pred_proba.shape[1]\n",
    "\n",
    "y_test_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = cycle(['#1f77b4', '#d62728', '#2ca02c'])\n",
    "target_names = ['Normal', 'Sickle', 'Other']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{target_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate (1-Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "#plt.title('Courbes ROC par classe', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === ROC Curve (multi-classes) ===\n",
    "def plot_roc_curve(model, loader, name=\"Test\"):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # binarisation des labels\n",
    "    classes = np.unique(all_labels)\n",
    "    y_test = label_binarize(all_labels, classes=classes)\n",
    "    n_classes = y_test.shape[1]\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "\n",
    "    # courbe ROC pour chaque classe\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, i], all_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2,\n",
    "                 label=f\"{['Autres','Falciformes','Normales'][i]} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    # micro-avg\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), all_probs.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=\"black\", linestyle=\"--\",\n",
    "             label=f\"Micro-average (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    plt.plot([0,1],[0,1],'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
    "    plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
    "    plt.title(f\"Courbe ROC - {name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# === Utilisation ===\n",
    "plot_roc_curve(model, test_loader, name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === ROC Curve (multi-classes) ===\n",
    "def plot_roc_curve(model, loader, name=\"Test\"):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # binarisation des labels\n",
    "    classes = np.unique(all_labels)\n",
    "    y_test = label_binarize(all_labels, classes=classes)\n",
    "    n_classes = y_test.shape[1]\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "\n",
    "    # courbe ROC pour chaque classe\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test[:, i], all_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2,\n",
    "                 label=f\"{['Autres','Falciformes','Normales'][i]} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    # micro-avg\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), all_probs.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=\"black\", linestyle=\"--\",\n",
    "             label=f\"Micro-average (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    plt.plot([0,1],[0,1],'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
    "    plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
    "    plt.title(f\"Courbe ROC - {name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# === Utilisation ===\n",
    "plot_roc_curve(model, test_loader, name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision–Recall (PR) curve multi-classes sur le jeu de test, avec l’Average Precision (AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Adapte si besoin à l’ordre de tes labels\n",
    "TARGET_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "\n",
    "def plot_pr_curve(model, loader, name=\"Test\"):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Binarisation des labels\n",
    "    classes = np.unique(all_labels)\n",
    "    y_true = label_binarize(all_labels, classes=classes)\n",
    "    n_classes = y_true.shape[1]\n",
    "\n",
    "    # Noms des classes (si dispo)\n",
    "    if len(TARGET_NAMES) == n_classes:\n",
    "        class_names = TARGET_NAMES\n",
    "    else:\n",
    "        class_names = [f\"Classe {c}\" for c in classes]\n",
    "\n",
    "    # AP par classe\n",
    "    ap_per_class = []\n",
    "    plt.figure(figsize=(7,6))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, _ = precision_recall_curve(y_true[:, i], all_probs[:, i])\n",
    "        ap = average_precision_score(y_true[:, i], all_probs[:, i])\n",
    "        ap_per_class.append(ap)\n",
    "        plt.plot(recall, precision, lw=2, label=f\"{class_names[i]} (AP = {ap:.3f})\")\n",
    "\n",
    "    # Micro-average (global, tous labels confondus)\n",
    "    precision_micro, recall_micro, _ = precision_recall_curve(y_true.ravel(), all_probs.ravel())\n",
    "    ap_micro = average_precision_score(y_true, all_probs, average=\"micro\")\n",
    "    plt.plot(recall_micro, precision_micro, linestyle=\"--\", lw=2,\n",
    "             label=f\"Micro-average (AP = {ap_micro:.3f})\")\n",
    "\n",
    "    # Macro-average (moyenne simple des AP par classe)\n",
    "    ap_macro = float(np.mean(ap_per_class))\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision–Recall Curve - {name} (macro AP = {ap_macro:.3f})\")\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "\n",
    "# === Utilisation sur le test ===\n",
    "plot_pr_curve(model, test_loader, name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interprétation du model avec Grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Grad-CAM classique pour un module convolutionnel cible.\n",
    "    target_layer: nn.Module (ex: model.cnn.layer4[-1])\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        # Hooks\n",
    "        self.fwd_hook = target_layer.register_forward_hook(self._save_activations)\n",
    "        # full_backward_hook (>=1.8). Si erreur, remplace par register_backward_hook\n",
    "        self.bwd_hook = target_layer.register_full_backward_hook(self._save_gradients)\n",
    "\n",
    "    def _save_activations(self, module, input, output):\n",
    "        # output: (B, C, H, W)\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _save_gradients(self, module, grad_input, grad_output):\n",
    "        # grad_output[0]: (B, C, H, W)\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        self.fwd_hook.remove()\n",
    "        self.bwd_hook.remove()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _normalize(self, cam):\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "    def __call__(self, images, targets=None, device=None):\n",
    "        \"\"\"\n",
    "        images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "        targets: liste/tensor de classes cibles (B,) ou None (=classe prédite)\n",
    "        return: heatmaps (B,H,W) dans [0,1]\n",
    "        \"\"\"\n",
    "        device = device or next(self.model.parameters()).device\n",
    "        images = images.to(device)\n",
    "\n",
    "        # FORWARD\n",
    "        outputs = self.model(images)  # (B, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        if targets is None:\n",
    "            targets = preds\n",
    "        else:\n",
    "            targets = torch.as_tensor(targets, device=device)\n",
    "\n",
    "        # BACKWARD sur le logit de la classe cible (pas la prob)\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        selected = outputs.gather(1, targets.view(-1,1)).sum()\n",
    "        selected.backward()\n",
    "\n",
    "        # activations: (B,C,H,W), gradients: (B,C,H,W)\n",
    "        A = self.activations           # (B,C,H,W)\n",
    "        dA = self.gradients            # (B,C,H,W)\n",
    "        B, C, H, W = A.shape\n",
    "\n",
    "        # poids: moyenne spatiale des gradients\n",
    "        weights = dA.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)  # (B,C,1,1)\n",
    "        cam = (weights * A).sum(dim=1)                            # (B,H,W)\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # normalisation par image\n",
    "        heatmaps = torch.stack([self._normalize(cam[i]) for i in range(B)], dim=0)  # (B,H,W)\n",
    "        return heatmaps.cpu(), preds.cpu(), probs.detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam(images, heatmaps, true_labels=None, pred_labels=None, class_names=None, cols=4):\n",
    "    \"\"\"\n",
    "    images: tensor (B,3,H,W) ou (B,1,H,W) en 0-1 (si ce n'est pas le cas, clamp/normalize avant)\n",
    "    heatmaps: tensor (B,H,W) en [0,1]\n",
    "    \"\"\"\n",
    "    imgs = images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  # grayscale -> répéter pour affichage couleur\n",
    "        imgs = imgs.repeat(1,3,1,1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(4*cols, 4*rows))\n",
    "\n",
    "    for i in range(B):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = np.transpose(imgs[i].numpy(), (1,2,0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        # overlay: image + heatmap (rouge) via alpha\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')  # alpha fixe\n",
    "        title = \"\"\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title += f\"Pred: {class_names[int(pred_labels[i])]}\"\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title += f\"\\nTrue: {class_names[int(true_labels[i])]}\"\n",
    "        plt.title(title.strip(), fontsize=10)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam_with_original(images, heatmaps, true_labels=None, pred_labels=None,\n",
    "                               class_names=None, scores=None, score_name=\"p\", cols=4):\n",
    "    \"\"\"\n",
    "    Affiche l'image originale + la superposition Grad-CAM côte à côte.\n",
    "    images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "    heatmaps: tensor (B,H,W)\n",
    "    \"\"\"\n",
    "    imgs = images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  # grayscale → RGB\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(8*cols, 4*rows))  # 2x plus large car 2 colonnes par image\n",
    "\n",
    "    for i in range(B):\n",
    "        img = np.transpose(imgs[i].numpy(), (1, 2, 0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        # --- Image originale ---\n",
    "        plt.subplot(rows, cols*2, 2*i+1)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        title_parts = []\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # --- Image avec heatmap ---\n",
    "        plt.subplot(rows, cols*2, 2*i+2)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')\n",
    "\n",
    "        title_parts = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_parts.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paramètres ---\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]  # adapte à ton mapping\n",
    "device = Config.DEVICE\n",
    "\n",
    "# --- Choix de la couche cible ---\n",
    "# Exemple si ton HybridModel a un backbone ResNet sous model.cnn\n",
    "target_layer = model.cnn.layer4[-1]   # <-- adapte selon ta classe\n",
    "\n",
    "# --- Instancier Grad-CAM ---\n",
    "cam = GradCAM(model.to(device).eval(), target_layer=target_layer)\n",
    "\n",
    "# --- Récupérer un mini-batch du test pour visualisation ---\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images = batch_images.to(device)\n",
    "batch_labels = batch_labels.to(device)\n",
    "\n",
    "# (Option) choisir les classes cibles = vraies étiquettes pour voir l'explication \"correcte\"\n",
    "# sinon, mets targets=None pour expliquer la classe prédite\n",
    "heatmaps, preds, probs = cam(batch_images, targets=batch_labels, device=device)\n",
    "\n",
    "# --- Afficher ---\n",
    "show_gradcam(batch_images, heatmaps, true_labels=batch_labels.cpu(),\n",
    "             pred_labels=preds, class_names=CLASS_NAMES, cols=4)\n",
    "\n",
    "# --- Nettoyer les hooks si tu n'en as plus besoin ---\n",
    "cam.remove_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paramètres ---\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]  # adapte à ton mapping\n",
    "device = Config.DEVICE\n",
    "\n",
    "# --- Choix de la couche cible ---\n",
    "# Exemple si ton HybridModel a un backbone ResNet sous model.cnn\n",
    "target_layer = model.cnn.layer4[-1]   # <-- adapte selon ta classe\n",
    "\n",
    "# --- Instancier Grad-CAM ---\n",
    "cam = GradCAM(model.to(device).eval(), target_layer=target_layer)\n",
    "\n",
    "# --- Récupérer un mini-batch du test pour visualisation ---\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images = batch_images.to(device)\n",
    "batch_labels = batch_labels.to(device)\n",
    "\n",
    "# (Option) choisir les classes cibles = vraies étiquettes pour voir l'explication \"correcte\"\n",
    "# sinon, mets targets=None pour expliquer la classe prédite\n",
    "heatmaps, preds, probs = cam(batch_images, targets=batch_labels, device=device)\n",
    "\n",
    "# --- Afficher ---\n",
    "show_gradcam(batch_images, heatmaps, true_labels=batch_labels.cpu(),\n",
    "             pred_labels=preds, class_names=CLASS_NAMES, cols=4)\n",
    "\n",
    "# --- Nettoyer les hooks si tu n'en as plus besoin ---\n",
    "cam.remove_hooks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam(images, heatmaps, true_labels=None, pred_labels=None,\n",
    "                 class_names=None, cols=4, scores=None, score_name=\"p\"):\n",
    "    \"\"\"\n",
    "    images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "    heatmaps: tensor (B,H,W)\n",
    "    scores: array-like (B,) -> affiché comme score_name=0.987 (ex. proba)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    imgs = images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  # si grayscale, répéter pour affichage couleur\n",
    "        imgs = imgs.repeat(1,3,1,1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(4*cols, 4*rows))\n",
    "\n",
    "    for i in range(B):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img = np.transpose(imgs[i].numpy(), (1,2,0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')\n",
    "\n",
    "        title_parts = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_parts.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam_with_original(images, heatmaps, true_labels=None, pred_labels=None,\n",
    "                               class_names=None, scores=None, score_name=\"p\", cols=4):\n",
    "    \"\"\"\n",
    "    Affiche l'image originale + la superposition Grad-CAM côte à côte.\n",
    "    images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "    heatmaps: tensor (B,H,W)\n",
    "    \"\"\"\n",
    "    imgs = images.detach().cpu()\n",
    "    if imgs.shape[1] == 1:  # grayscale → RGB\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(8*cols, 4*rows))  # 2x plus large car 2 colonnes par image\n",
    "\n",
    "    for i in range(B):\n",
    "        img = np.transpose(imgs[i].numpy(), (1, 2, 0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        # --- Image originale ---\n",
    "        plt.subplot(rows, cols*2, 2*i+1)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        title_parts = []\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # --- Image avec heatmap ---\n",
    "        plt.subplot(rows, cols*2, 2*i+2)\n",
    "        plt.imshow(img, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.4, interpolation='bilinear')\n",
    "\n",
    "        title_parts = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_parts.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_parts.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "        plt.title(\" | \".join(title_parts), fontsize=9)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gradcam_with_original(batch_images, heatmaps,\n",
    "                           true_labels=batch_labels.cpu(),\n",
    "                           pred_labels=preds,\n",
    "                           class_names=CLASS_NAMES,\n",
    "                           scores=conf_pred,\n",
    "                           score_name=\"p_pred\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_pred = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "show_gradcam(batch_images, heatmaps,\n",
    "             true_labels=batch_labels, pred_labels=preds,\n",
    "             class_names=CLASS_NAMES, cols=4,\n",
    "             scores=conf_pred, score_name=\"p_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Si tes images ont été normalisées comme ImageNet :\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "def denormalize(img_tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n",
    "    \"\"\"\n",
    "    img_tensor: (C,H,W) torch.Tensor\n",
    "    Retourne un numpy (H,W,C) clampé dans [0,1] pour affichage.\n",
    "    \"\"\"\n",
    "    x = img_tensor.detach().cpu().float()\n",
    "    if x.shape[0] == 1:  # grayscale -> afficher en pseudo-RGB\n",
    "        x = x.repeat(3,1,1)\n",
    "    m = torch.tensor(mean).view(-1,1,1)\n",
    "    s = torch.tensor(std).view(-1,1,1)\n",
    "    x = (x * s) + m\n",
    "    x = x.clamp(0,1)\n",
    "    return np.transpose(x.numpy(), (1,2,0))\n",
    "\n",
    "def pick_indices_per_class(labels, class_ids, k_per_class=3):\n",
    "    \"\"\"\n",
    "    labels: tensor/ndarray (B,)\n",
    "    class_ids: liste des ids de classes à couvrir (ex: [0,1,2])\n",
    "    Retourne jusqu'à k_per_class indices par classe.\n",
    "    \"\"\"\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    idxs = []\n",
    "    for c in class_ids:\n",
    "        pool = np.where(labels == c)[0]\n",
    "        if len(pool) > 0:\n",
    "            k = min(k_per_class, len(pool))\n",
    "            chosen = np.random.choice(pool, size=k, replace=False)\n",
    "            idxs.extend(chosen.tolist())\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam_side_by_side(images, heatmaps,\n",
    "                              true_labels=None, pred_labels=None,\n",
    "                              class_names=None, indices=None, k_per_class=3,\n",
    "                              choose_by=\"pred\"):\n",
    "    \"\"\"\n",
    "    images    : (B,C,H,W) torch.Tensor\n",
    "    heatmaps  : (B,H,W)   torch.Tensor (normalisés 0..1 par ta classe GradCAM)\n",
    "    choose_by : \"pred\" -> sélection par classe prédite, \"true\" -> classe vraie\n",
    "    indices   : liste d'indices pour forcer l'affichage (sinon on choisit par classe)\n",
    "    \"\"\"\n",
    "    imgs = images.detach().cpu()\n",
    "    hmaps = heatmaps.detach().cpu().numpy() if isinstance(heatmaps, torch.Tensor) else heatmaps\n",
    "\n",
    "    # Déterminer quelles classes couvrir\n",
    "    if class_names is None:\n",
    "        raise ValueError(\"Fournis class_names dans le même ordre que tes labels.\")\n",
    "    class_ids = np.arange(len(class_names))\n",
    "\n",
    "    # Choisir les indices à afficher\n",
    "    if indices is None:\n",
    "        base = pred_labels if choose_by == \"pred\" else true_labels\n",
    "        if base is None:\n",
    "            raise ValueError(\"choose_by='pred' nécessite pred_labels, 'true' nécessite true_labels.\")\n",
    "        indices = pick_indices_per_class(base, class_ids, k_per_class=k_per_class)\n",
    "\n",
    "    n = len(indices)\n",
    "    cols = 2  # Original | Grad-CAM\n",
    "    rows = int(np.ceil(n))\n",
    "    plt.figure(figsize=(6*cols, 3*rows))\n",
    "\n",
    "    for j, idx in enumerate(indices):\n",
    "        img_np = denormalize(imgs[idx])  # on n'altère PAS le heatmap\n",
    "        hm = hmaps[idx]\n",
    "\n",
    "        # Titres\n",
    "        title_lines = []\n",
    "        if pred_labels is not None:\n",
    "            title_lines.append(f\"Pred: {class_names[int(pred_labels[idx])]}\")\n",
    "        if true_labels is not None:\n",
    "            title_lines.append(f\"True: {class_names[int(true_labels[idx])]}\")\n",
    "        title = \" | \".join(title_lines)\n",
    "\n",
    "        # Colonne 1 : Original\n",
    "        plt.subplot(rows, cols, 2*j + 1)\n",
    "        plt.imshow(img_np, interpolation='bilinear')\n",
    "        plt.title(f\"Original\\n{title}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Colonne 2 : Overlay Grad-CAM (heatmap inchangé)\n",
    "        plt.subplot(rows, cols, 2*j + 2)\n",
    "        plt.imshow(img_np, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.40, interpolation='bilinear')\n",
    "        plt.title(f\"Grad-CAM\\n{title}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère un batch du test\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images = batch_images.to(device)\n",
    "batch_labels = batch_labels.to(device)\n",
    "\n",
    "# Grad-CAM (sur la classe prédite pour chaque image)\n",
    "heatmaps, preds, probs = cam(batch_images, targets=None, device=device)\n",
    "\n",
    "# Afficher k images par classe prédite (ex: 3) : toutes les classes seront représentées si présentes dans le batch\n",
    "show_gradcam_side_by_side(batch_images, heatmaps,\n",
    "                          true_labels=batch_labels, pred_labels=preds,\n",
    "                          class_names=CLASS_NAMES,\n",
    "                          k_per_class=3, choose_by=\"pred\")\n",
    "\n",
    "# (Option) Sélection par classe VRAIE au lieu de prédite :\n",
    "# show_gradcam_side_by_side(batch_images, heatmaps,\n",
    "#                           true_labels=batch_labels, pred_labels=preds,\n",
    "#                           class_names=CLASS_NAMES,\n",
    "#                           k_per_class=3, choose_by=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_vector(probs, preds=None, targets=None):\n",
    "    \"\"\"\n",
    "    probs : torch.Tensor (B, num_classes)\n",
    "    preds : Tensor (B,) classes prédites\n",
    "    targets : Tensor (B,) classes vraies\n",
    "    Retour : np.array (B,) des probabilités correspondantes\n",
    "    \"\"\"\n",
    "    probs_np = probs.detach().cpu().numpy()\n",
    "    if preds is not None:\n",
    "        idx = preds.detach().cpu().numpy()\n",
    "    elif targets is not None:\n",
    "        idx = targets.detach().cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Fournir preds OU targets.\")\n",
    "    return probs_np[np.arange(len(probs_np)), idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradcam_side_by_side(images, heatmaps,\n",
    "                              true_labels=None, pred_labels=None,\n",
    "                              class_names=None, indices=None, k_per_class=3,\n",
    "                              choose_by=\"pred\",\n",
    "                              scores=None, score_name=\"p_pred\",\n",
    "                              extra_scores=None, extra_score_name=\"p_true\"):\n",
    "    \"\"\"\n",
    "    images       : (B,C,H,W)\n",
    "    heatmaps     : (B,H,W)\n",
    "    scores       : array-like (B,) -> affiché comme score_name=0.987 (ex: proba prédite)\n",
    "    extra_scores : array-like (B,) -> second score optionnel (ex: proba vraie)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    imgs = images.detach().cpu()\n",
    "    hmaps = heatmaps.detach().cpu().numpy() if isinstance(heatmaps, torch.Tensor) else heatmaps\n",
    "\n",
    "    if class_names is None:\n",
    "        raise ValueError(\"Fournis class_names dans le même ordre que tes labels.\")\n",
    "    class_ids = np.arange(len(class_names))\n",
    "\n",
    "    # Choix indices\n",
    "    if indices is None:\n",
    "        base = pred_labels if choose_by == \"pred\" else true_labels\n",
    "        if base is None:\n",
    "            raise ValueError(\"choose_by='pred' nécessite pred_labels, 'true' nécessite true_labels.\")\n",
    "        indices = pick_indices_per_class(base, class_ids, k_per_class=k_per_class)\n",
    "\n",
    "    n = len(indices)\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(n))\n",
    "    plt.figure(figsize=(6*cols, 3*rows))\n",
    "\n",
    "    for j, idx in enumerate(indices):\n",
    "        img_np = denormalize(imgs[idx])\n",
    "        hm = hmaps[idx]\n",
    "\n",
    "        # Titre\n",
    "        title_parts = []\n",
    "        if pred_labels is not None:\n",
    "            title_parts.append(f\"Pred: {class_names[int(pred_labels[idx])]}\")\n",
    "        if true_labels is not None:\n",
    "            title_parts.append(f\"True: {class_names[int(true_labels[idx])]}\")\n",
    "        if scores is not None:\n",
    "            title_parts.append(f\"{score_name}={float(scores[idx]):.3f}\")\n",
    "        if extra_scores is not None:\n",
    "            title_parts.append(f\"{extra_score_name}={float(extra_scores[idx]):.3f}\")\n",
    "        title = \" | \".join(title_parts)\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(rows, cols, 2*j + 1)\n",
    "        plt.imshow(img_np, interpolation='bilinear')\n",
    "        plt.title(f\"Original\\n{title}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Grad-CAM overlay (heatmap inchangé)\n",
    "        plt.subplot(rows, cols, 2*j + 2)\n",
    "        plt.imshow(img_np, interpolation='bilinear')\n",
    "        plt.imshow(hm, cmap='jet', alpha=0.40, interpolation='bilinear')\n",
    "        plt.title(f\"Grad-CAM\\n{title}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch du test\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "\n",
    "# Grad-CAM (cible = classe prédite)\n",
    "heatmaps, preds, probs = cam(batch_images, targets=None, device=device)\n",
    "\n",
    "# Scores\n",
    "conf_pred = get_confidence_vector(probs, preds=preds)           # p_pred\n",
    "conf_true = get_confidence_vector(probs, targets=batch_labels)  # p_true\n",
    "\n",
    "# Afficher k images par classe prédite (ex: 3) avec les deux scores\n",
    "show_gradcam_side_by_side(batch_images, heatmaps,\n",
    "                          true_labels=batch_labels, pred_labels=preds,\n",
    "                          class_names=CLASS_NAMES,\n",
    "                          k_per_class=3, choose_by=\"pred\",\n",
    "                          scores=conf_pred, score_name=\"p_pred\",\n",
    "                          extra_scores=conf_true, extra_score_name=\"p_true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resolve_class_id_by_name(dataset, desired_names, fallback_idx):\n",
    "    \"\"\"\n",
    "    Essaie de retrouver l'ID d'une classe via dataset.class_to_idx\n",
    "    en testant plusieurs variantes de nom. Sinon renvoie fallback_idx.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, \"class_to_idx\"):\n",
    "        c2i = dataset.class_to_idx\n",
    "        for name in desired_names:\n",
    "            if name in c2i:\n",
    "                return c2i[name]\n",
    "    return fallback_idx\n",
    "\n",
    "def gather_k_examples_per_class(loader, class_id, k=10, device=None, ensure_k=True):\n",
    "    \"\"\"\n",
    "    Retourne EXACTEMENT k images/labels pour la classe `class_id`.\n",
    "    - Si < k dispo, répète des exemples jusqu'à k (ensure_k=True).\n",
    "    - Si > k dispo, tronque à k.\n",
    "    \"\"\"\n",
    "    imgs_list, labs_list = [], []\n",
    "    for images, labels in loader:\n",
    "        mask = (labels == class_id)\n",
    "        if mask.any():\n",
    "            imgs_list.append(images[mask])\n",
    "            labs_list.append(labels[mask])\n",
    "            # stop si on a déjà >= k en stock\n",
    "            if sum(t.size(0) for t in labs_list) >= k:\n",
    "                break\n",
    "\n",
    "    if not imgs_list:\n",
    "        raise RuntimeError(f\"Aucune image trouvée pour la classe id={class_id}.\")\n",
    "\n",
    "    imgs = torch.cat(imgs_list, dim=0)\n",
    "    labs = torch.cat(labs_list, dim=0)\n",
    "\n",
    "    n = imgs.size(0)\n",
    "    if n >= k:\n",
    "        imgs = imgs[:k]\n",
    "        labs = labs[:k]\n",
    "    else:\n",
    "        if ensure_k:\n",
    "            # Répéter pour atteindre k\n",
    "            reps = (k + n - 1) // n  # plafond(k/n)\n",
    "            imgs = imgs.repeat((reps, 1, 1, 1))[:k]\n",
    "            labs = labs.repeat(reps)[:k]\n",
    "            print(f\"[Info] Classe {class_id}: {n} trouvées < {k}, répétition pour atteindre {k}.\")\n",
    "        else:\n",
    "            # On garde n < k, l'affichage gérera les colonnes vides\n",
    "            print(f\"[Info] Classe {class_id}: seulement {n}/{k} images disponibles.\")\n",
    "\n",
    "    if device is not None:\n",
    "        imgs = imgs.to(device)\n",
    "        labs = labs.to(device)\n",
    "    return imgs, labs\n",
    "\n",
    "def plot_gradcam_10_per_class(\n",
    "    cam,\n",
    "    loader,\n",
    "    class_names=(\"Autres\",\"Falciformes\",\"Normales\"),\n",
    "    k_per_class=10,\n",
    "    save_path=\"gradcam_10_per_class.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None,\n",
    "    denorm_std=None,\n",
    "    show_pred_scores=True,\n",
    "    dpi=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Figure: 6 rangées x k_per_class colonnes (par classe: Original + Grad-CAM).\n",
    "    Garantit exactement k_per_class par classe (répétition si nécessaire).\n",
    "    \"\"\"\n",
    "    ds = loader.dataset if hasattr(loader, \"dataset\") else None\n",
    "\n",
    "    autres_id = resolve_class_id_by_name(ds, [\"Autres\",\"Other\",\"Others\"], fallback_idx=class_names.index(\"Autres\"))\n",
    "    falci_id  = resolve_class_id_by_name(ds, [\"Falciformes\",\"Sickle\",\"Sickled\",\"Sickle Cells\"], fallback_idx=class_names.index(\"Falciformes\"))\n",
    "    normal_id = resolve_class_id_by_name(ds, [\"Normales\",\"Normal\",\"Normals\"], fallback_idx=class_names.index(\"Normales\"))\n",
    "\n",
    "    # Récupération + Grad-CAM pour chaque classe (EXACTEMENT k_per_class)\n",
    "    per_class = []\n",
    "    for cid in (autres_id, falci_id, normal_id):\n",
    "        imgs, labs = gather_k_examples_per_class(\n",
    "            loader, class_id=cid, k=k_per_class,\n",
    "            device=next(cam.model.parameters()).device, ensure_k=True\n",
    "        )\n",
    "        heatmaps, preds, probs = cam(imgs, targets=labs)  # explique la VÉRITÉ\n",
    "        # Sécuriser la taille à k_per_class (au cas où)\n",
    "        heatmaps = heatmaps[:k_per_class]\n",
    "        preds    = preds[:k_per_class]\n",
    "        probs    = probs[:k_per_class]\n",
    "\n",
    "        confs = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "        disp = imgs\n",
    "        if disp.shape[1] == 1:\n",
    "            disp = disp.repeat(1, 3, 1, 1)\n",
    "        disp = denormalize(disp, mean=denorm_mean, std=denorm_std)\n",
    "        disp = disp[:k_per_class]\n",
    "\n",
    "        per_class.append((disp.cpu().numpy(), heatmaps.cpu().numpy(), preds.cpu().numpy(), confs))\n",
    "\n",
    "    # Construction de la figure\n",
    "    rows, cols = 6, k_per_class\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(2.1*cols, 2.1*rows))\n",
    "    if rows == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    # Noms propres (affichage) dans l'ordre Autres, Falciformes, Normales\n",
    "    display_names = [\n",
    "        class_names[class_names.index(\"Autres\")],\n",
    "        class_names[class_names.index(\"Falciformes\")],\n",
    "        class_names[class_names.index(\"Normales\")],\n",
    "    ]\n",
    "\n",
    "    for class_idx, (disp, heat, preds, confs) in enumerate(per_class):\n",
    "        top_row = 2*class_idx       # originales\n",
    "        bot_row = 2*class_idx + 1   # overlays\n",
    "\n",
    "        # Boucle sur EXACTEMENT k_per_class colonnes\n",
    "        for j in range(k_per_class):\n",
    "            # sécurité : si jamais un décalage survient, on coupe\n",
    "            if j >= disp.shape[0] or j >= heat.shape[0]:\n",
    "                # masquer cellule\n",
    "                axes[top_row, j].axis(\"off\")\n",
    "                axes[bot_row, j].axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            img = np.transpose(disp[j], (1, 2, 0))\n",
    "            hm  = heat[j]\n",
    "\n",
    "            # Original\n",
    "            ax = axes[top_row, j]\n",
    "            ax.imshow(img, interpolation=\"bilinear\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"{display_names[class_idx]}\\nOriginal\", fontsize=10)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "            # Grad-CAM\n",
    "            ax = axes[bot_row, j]\n",
    "            ax.imshow(img, interpolation=\"bilinear\")\n",
    "            ax.imshow(hm, cmap=\"jet\", alpha=overlay_alpha, interpolation=\"bilinear\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(\"Grad-CAM\", fontsize=10)\n",
    "            if show_pred_scores:\n",
    "                ax.set_title(f\"Pred: {class_names[int(preds[j])]} (p={confs[j]:.2f})\", fontsize=8)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "    fig.suptitle(\"Grad-CAM — 10 images par classe (Original & Overlay)\", fontsize=12)\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"[OK] Figure enregistrée : {save_path}\")\n",
    "\n",
    "# Optionnel : si tes images sont normalisées ImageNet\n",
    "# IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "plot_gradcam_10_per_class(\n",
    "    cam, test_loader, class_names=CLASS_NAMES, k_per_class=10,\n",
    "    save_path=\"gradcam_10_per_class.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None, denorm_std=None,   # mets IMAGENET_MEAN/STD si besoin\n",
    "    show_pred_scores=True, dpi=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resolve_class_id_by_name(dataset, desired_names, fallback_idx):\n",
    "    \"\"\"\n",
    "    Essaie de retrouver l'ID d'une classe via dataset.class_to_idx\n",
    "    en testant plusieurs variantes de nom. Sinon renvoie fallback_idx.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, \"class_to_idx\"):\n",
    "        c2i = dataset.class_to_idx\n",
    "        for name in desired_names:\n",
    "            if name in c2i:\n",
    "                return c2i[name]\n",
    "    return fallback_idx\n",
    "\n",
    "def gather_k_examples_per_class(loader, class_id, k=10, device=None, ensure_k=True):\n",
    "    \"\"\"\n",
    "    Retourne EXACTEMENT k images/labels pour la classe `class_id`.\n",
    "    - Si < k dispo, répète des exemples jusqu'à k (ensure_k=True).\n",
    "    - Si > k dispo, tronque à k.\n",
    "    \"\"\"\n",
    "    imgs_list, labs_list = [], []\n",
    "    for images, labels in loader:\n",
    "        mask = (labels == class_id)\n",
    "        if mask.any():\n",
    "            imgs_list.append(images[mask])\n",
    "            labs_list.append(labels[mask])\n",
    "            # stop si on a déjà >= k en stock\n",
    "            if sum(t.size(0) for t in labs_list) >= k:\n",
    "                break\n",
    "\n",
    "    if not imgs_list:\n",
    "        raise RuntimeError(f\"Aucune image trouvée pour la classe id={class_id}.\")\n",
    "\n",
    "    imgs = torch.cat(imgs_list, dim=0)\n",
    "    labs = torch.cat(labs_list, dim=0)\n",
    "\n",
    "    n = imgs.size(0)\n",
    "    if n >= k:\n",
    "        imgs = imgs[:k]\n",
    "        labs = labs[:k]\n",
    "    else:\n",
    "        if ensure_k:\n",
    "            # Répéter pour atteindre k\n",
    "            reps = (k + n - 1) // n  # plafond(k/n)\n",
    "            imgs = imgs.repeat((reps, 1, 1, 1))[:k]\n",
    "            labs = labs.repeat(reps)[:k]\n",
    "            print(f\"[Info] Classe {class_id}: {n} trouvées < {k}, répétition pour atteindre {k}.\")\n",
    "        else:\n",
    "            # On garde n < k, l'affichage gérera les colonnes vides\n",
    "            print(f\"[Info] Classe {class_id}: seulement {n}/{k} images disponibles.\")\n",
    "\n",
    "    if device is not None:\n",
    "        imgs = imgs.to(device)\n",
    "        labs = labs.to(device)\n",
    "    return imgs, labs\n",
    "\n",
    "def plot_gradcam_10_per_class(\n",
    "    cam,\n",
    "    loader,\n",
    "    class_names=(\"Others\", \"Sickle Cells\", \"Normals\"),\n",
    "    k_per_class=10,\n",
    "    save_path=\"gradcam_10_per_class.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None,\n",
    "    denorm_std=None,\n",
    "    show_pred_scores=True,\n",
    "    dpi=300,\n",
    "    label_inside=True  # ← True = text inside the image, False = as axis title\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a 6-row x k-column figure showing 10 images per class:\n",
    "      - For each class: top row = original images, bottom row = Grad-CAM overlays.\n",
    "    Ensures exactly k_per_class per class (repeats samples if needed).\n",
    "    Saves a high-resolution PNG for papers.\n",
    "\n",
    "    Args:\n",
    "        cam: GradCAM instance (callable) -> returns (heatmaps, preds, probs).\n",
    "        loader: DataLoader (ideally your test loader).\n",
    "        class_names: tuple/list of class display names (len = num_classes).\n",
    "        k_per_class: number of examples to display per class.\n",
    "        save_path: output PNG path.\n",
    "        overlay_alpha: transparency for the heatmap overlay.\n",
    "        denorm_mean, denorm_std: use if images were normalized (e.g., ImageNet stats).\n",
    "        show_pred_scores: whether to show predicted label + prob.\n",
    "        dpi: output figure DPI.\n",
    "        label_inside: True to draw text inside the image (never cut), False to use axis title.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # --- Utilities -----------------------------------------------------------\n",
    "    def fallback_from_candidates(names, candidates, default_idx=0):\n",
    "        \"\"\"Pick the first candidate present in `names`; otherwise return default_idx.\"\"\"\n",
    "        for nm in candidates:\n",
    "            if nm in names:\n",
    "                return names.index(nm)\n",
    "        return default_idx\n",
    "\n",
    "    def resolve_class_id_by_name(dataset, desired_names, fallback_candidates, default_idx=0):\n",
    "        \"\"\"\n",
    "        Try to resolve a class id via dataset.class_to_idx using any of `desired_names`.\n",
    "        If not found, fall back to the first match within class_names from `fallback_candidates`.\n",
    "        \"\"\"\n",
    "        if hasattr(dataset, \"class_to_idx\"):\n",
    "            c2i = dataset.class_to_idx\n",
    "            for nm in desired_names:\n",
    "                if nm in c2i:\n",
    "                    return c2i[nm]\n",
    "        # Fallback using provided display class_names\n",
    "        return fallback_from_candidates(class_names, fallback_candidates, default_idx=default_idx)\n",
    "\n",
    "    def gather_k_examples_per_class(loader, class_id, k=10, device=None, ensure_k=True):\n",
    "        \"\"\"\n",
    "        Return EXACTLY k images/labels for a given class_id.\n",
    "        - If fewer than k are available and ensure_k=True, repeat samples to reach k.\n",
    "        - If more are available, truncate to k.\n",
    "        \"\"\"\n",
    "        imgs_list, labs_list = [], []\n",
    "        for images, labels in loader:\n",
    "            mask = (labels == class_id)\n",
    "            if mask.any():\n",
    "                imgs_list.append(images[mask])\n",
    "                labs_list.append(labels[mask])\n",
    "                if sum(t.size(0) for t in labs_list) >= k:\n",
    "                    break\n",
    "        if not imgs_list:\n",
    "            raise RuntimeError(f\"No image found for class id={class_id}.\")\n",
    "        imgs = torch.cat(imgs_list, dim=0)\n",
    "        labs = torch.cat(labs_list, dim=0)\n",
    "\n",
    "        n = imgs.size(0)\n",
    "        if n >= k:\n",
    "            imgs = imgs[:k]; labs = labs[:k]\n",
    "        else:\n",
    "            if ensure_k:\n",
    "                reps = (k + n - 1) // n  # ceil(k/n)\n",
    "                imgs = imgs.repeat((reps, 1, 1, 1))[:k]\n",
    "                labs = labs.repeat(reps)[:k]\n",
    "                print(f\"[Info] Class {class_id}: found {n} < {k}, repeating to reach {k}.\")\n",
    "            # else: keep <k and leave blanks (not used here)\n",
    "\n",
    "        if device is not None:\n",
    "            imgs = imgs.to(device); labs = labs.to(device)\n",
    "        return imgs, labs\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    ds = loader.dataset if hasattr(loader, \"dataset\") else None\n",
    "\n",
    "    # Build a reliable index->name mapping (prefer dataset ordering if present)\n",
    "    if hasattr(ds, \"class_to_idx\"):\n",
    "        idx_to_name = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    else:\n",
    "        idx_to_name = {i: n for i, n in enumerate(class_names)}\n",
    "\n",
    "    # Resolve class IDs robustly (accept English & French synonyms)\n",
    "    others_id = resolve_class_id_by_name(\n",
    "        ds,\n",
    "        desired_names=[\"Others\", \"Other\", \"Autres\"],\n",
    "        fallback_candidates=[\"Others\", \"Other\", \"Autres\"],\n",
    "        default_idx=0\n",
    "    )\n",
    "    sickle_id = resolve_class_id_by_name(\n",
    "        ds,\n",
    "        desired_names=[\"Sickle Cells\", \"Sickled\", \"Sickle\", \"Falciformes\"],\n",
    "        fallback_candidates=[\"Sickle Cells\", \"Sickled\", \"Sickle\", \"Falciformes\"],\n",
    "        default_idx=1\n",
    "    )\n",
    "    normal_id = resolve_class_id_by_name(\n",
    "        ds,\n",
    "        desired_names=[\"Normals\", \"Normal\", \"Normales\"],\n",
    "        fallback_candidates=[\"Normals\", \"Normal\", \"Normales\"],\n",
    "        default_idx=2\n",
    "    )\n",
    "\n",
    "    # Collect and compute Grad-CAM for each class (exactly k_per_class)\n",
    "    per_class = []\n",
    "    for cid in (others_id, sickle_id, normal_id):\n",
    "        imgs, labs = gather_k_examples_per_class(\n",
    "            loader, class_id=cid, k=k_per_class,\n",
    "            device=next(cam.model.parameters()).device, ensure_k=True\n",
    "        )\n",
    "        heatmaps, preds, probs = cam(imgs, targets=labs)  # explain the GROUND TRUTH (targets=labs)\n",
    "        heatmaps = heatmaps[:k_per_class]\n",
    "        preds    = preds[:k_per_class]\n",
    "        probs    = probs[:k_per_class]\n",
    "        confs = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "        disp = imgs\n",
    "        if disp.shape[1] == 1:\n",
    "            disp = disp.repeat(1, 3, 1, 1)\n",
    "        disp = denormalize(disp, mean=denorm_mean, std=denorm_std)[:k_per_class]\n",
    "\n",
    "        per_class.append((disp.cpu().numpy(), heatmaps.cpu().numpy(), preds.cpu().numpy(), confs))\n",
    "\n",
    "    # Build figure: 6 rows (Original/Grad-CAM per class) x k columns\n",
    "    rows, cols = 6, k_per_class\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(2.2*cols, 2.4*rows), constrained_layout=True)\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    # Display names (in the order: Others, Sickle Cells, Normals)\n",
    "    display_names = [\n",
    "        fallback_from_candidates(class_names, [\"Others\", \"Other\", \"Autres\"], default_idx=0)  or 0,\n",
    "        fallback_from_candidates(class_names, [\"Sickle Cells\", \"Sickled\", \"Sickle\", \"Falciformes\"], default_idx=1) or 1,\n",
    "        fallback_from_candidates(class_names, [\"Normals\", \"Normal\", \"Normales\"], default_idx=2)  or 2,\n",
    "    ]\n",
    "    # convert indices → names\n",
    "    display_names = [class_names[i] if 0 <= i < len(class_names) else f\"class_{i}\" for i in display_names]\n",
    "\n",
    "    for class_idx, (disp, heat, preds, confs) in enumerate(per_class):\n",
    "        top_row = 2 * class_idx\n",
    "        bot_row = 2 * class_idx + 1\n",
    "\n",
    "        for j in range(k_per_class):\n",
    "            if j >= disp.shape[0] or j >= heat.shape[0]:\n",
    "                axes[top_row, j].axis(\"off\")\n",
    "                axes[bot_row, j].axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            img = np.transpose(disp[j], (1, 2, 0))\n",
    "            hm  = heat[j]\n",
    "\n",
    "            # Original\n",
    "            ax = axes[top_row, j]\n",
    "            ax.imshow(img, interpolation=\"bilinear\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"{display_names[class_idx]}\\nOriginal\", fontsize=10)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "            # Grad-CAM\n",
    "            ax = axes[bot_row, j]\n",
    "            ax.imshow(img, interpolation=\"bilinear\")\n",
    "            ax.imshow(hm, cmap=\"jet\", alpha=overlay_alpha, interpolation=\"bilinear\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(\"Grad-CAM\", fontsize=10)\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "\n",
    "            if show_pred_scores:\n",
    "                pred_idx = int(preds[j])\n",
    "                # robust predicted class name\n",
    "                pred_name = idx_to_name.get(\n",
    "                    pred_idx,\n",
    "                    class_names[pred_idx] if 0 <= pred_idx < len(class_names) else f\"class_{pred_idx}\"\n",
    "                )\n",
    "                conf_val = float(confs[j]) if np.isfinite(confs[j]) else float(\"nan\")\n",
    "\n",
    "                if label_inside:\n",
    "                    # text inside the image (never cut off)\n",
    "                    ax.text(\n",
    "                        0.02, 0.98,\n",
    "                        f\"Pred: {pred_name}\\n(p={conf_val:.2f})\",\n",
    "                        transform=ax.transAxes,\n",
    "                        va=\"top\", ha=\"left\",\n",
    "                        fontsize=8,\n",
    "                        bbox=dict(facecolor=\"white\", alpha=0.65, edgecolor=\"none\")\n",
    "                    )\n",
    "                else:\n",
    "                    # axis title (can be compressed in tight layouts)\n",
    "                    ax.set_title(f\"Pred: {pred_name} (p={conf_val:.2f})\", fontsize=8, pad=2)\n",
    "\n",
    "    fig.suptitle(\"Grad-CAM — 10 images per class (Original & Overlay)\", fontsize=12)\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"[OK] Saved figure: {save_path}\")\n",
    "\n",
    "# Optionnel : si tes images sont normalisées ImageNet\n",
    "# IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "plot_gradcam_10_per_class(\n",
    "    cam, test_loader, class_names=CLASS_NAMES, k_per_class=10,\n",
    "    save_path=\"gradcam_10_per_class.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None, denorm_std=None,   # mets IMAGENET_MEAN/STD si besoin\n",
    "    show_pred_scores=True, dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Panel unique 3 classes (1 figure)\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optionnel : si tes images sont normalisées ImageNet, décommente :\n",
    "# IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "def resolve_class_id_by_name(dataset, desired_names, fallback_idx):\n",
    "    \"\"\"\n",
    "    desired_names: liste de noms candidats pour une même classe.\n",
    "    Renvoie l'ID trouvé via dataset.class_to_idx, sinon fallback_idx.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, \"class_to_idx\"):\n",
    "        c2i = dataset.class_to_idx\n",
    "        for name in desired_names:\n",
    "            if name in c2i:\n",
    "                return c2i[name]\n",
    "    return fallback_idx\n",
    "\n",
    "def gather_one_example_per_class(loader, class_ids, device=None):\n",
    "    \"\"\"\n",
    "    Retourne (imgs, labels) avec exactement 1 image par classe demandée (dans l'ordre).\n",
    "    Lève une erreur si aucune image trouvée pour une classe.\n",
    "    \"\"\"\n",
    "    found = {cid: None for cid in class_ids}\n",
    "    for images, labels in loader:\n",
    "        for cid in class_ids:\n",
    "            if found[cid] is None:\n",
    "                mask = (labels == cid)\n",
    "                if mask.any():\n",
    "                    idx = torch.nonzero(mask, as_tuple=False)[0].item()\n",
    "                    img = images[idx:idx+1]      # (1,C,H,W)\n",
    "                    lab = labels[idx:idx+1]      # (1,)\n",
    "                    found[cid] = (img, lab)\n",
    "        if all(v is not None for v in found.values()):\n",
    "            break\n",
    "\n",
    "    if not all(v is not None for v in found.values()):\n",
    "        missing = [cid for cid, v in found.items() if v is None]\n",
    "        raise RuntimeError(f\"Aucune image trouvée pour les classes: {missing}\")\n",
    "\n",
    "    imgs = torch.cat([found[cid][0] for cid in class_ids], dim=0)\n",
    "    labs = torch.cat([found[cid][1] for cid in class_ids], dim=0)\n",
    "    if device is not None:\n",
    "        imgs = imgs.to(device)\n",
    "        labs = labs.to(device)\n",
    "    return imgs, labs\n",
    "\n",
    "def plot_gradcam_panel_three_classes(\n",
    "    cam,\n",
    "    loader,\n",
    "    class_names=(\"Autres\",\"Falciformes\",\"Normales\"),\n",
    "    save_path=\"gradcam_3classes_panel.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None,\n",
    "    denorm_std=None,\n",
    "    show_pred_scores=True,\n",
    "    dpi=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Crée une figure unique : 2 rangées x 3 colonnes\n",
    "      - Rangée 1 : images originales (Autres, Falciformes, Normales)\n",
    "      - Rangée 2 : mêmes images avec Grad-CAM superposé\n",
    "    Sauvegarde en PNG haute résolution (dpi).\n",
    "    \"\"\"\n",
    "    ds = loader.dataset if hasattr(loader, \"dataset\") else None\n",
    "\n",
    "    # Résolution robuste des IDs (synonymes possibles)\n",
    "    autres_id = resolve_class_id_by_name(ds, [\"Autres\",\"Other\",\"Others\"], fallback_idx=class_names.index(\"Autres\"))\n",
    "    falci_id  = resolve_class_id_by_name(ds, [\"Falciformes\",\"Sickle\",\"Sickled\",\"Sickle Cells\"], fallback_idx=class_names.index(\"Falciformes\"))\n",
    "    normal_id = resolve_class_id_by_name(ds, [\"Normales\",\"Normal\",\"Normals\"], fallback_idx=class_names.index(\"Normales\"))\n",
    "    class_ids = [autres_id, falci_id, normal_id]\n",
    "\n",
    "    # Récupérer 1 exemple par classe (dans l'ordre)\n",
    "    imgs, labs = gather_one_example_per_class(loader, class_ids, device=next(cam.model.parameters()).device)\n",
    "\n",
    "    # Calcul Grad-CAM (targets = vraies étiquettes pour illustrer la classe correcte)\n",
    "    heatmaps, preds, probs = cam(imgs, targets=labs)\n",
    "    # Confiances de la classe prédite\n",
    "    conf_pred = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "    # Préparer images pour affichage\n",
    "    disp = imgs\n",
    "    if disp.shape[1] == 1:\n",
    "        disp = disp.repeat(1,3,1,1)\n",
    "    disp = denormalize(disp, mean=denorm_mean, std=denorm_std)  # ou laisse None si déjà dans [0,1]\n",
    "\n",
    "    # Figure : 2x3\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 7))\n",
    "    for j in range(3):\n",
    "        img = np.transpose(disp[j].cpu().numpy(), (1,2,0))\n",
    "        hm  = heatmaps[j].numpy()\n",
    "\n",
    "        # Rangée 1 : Original\n",
    "        ax = axes[0, j]\n",
    "        ax.imshow(img, interpolation=\"bilinear\")\n",
    "        ax.set_title(f\"{class_names[class_ids[j]]}\", fontsize=11)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Rangée 2 : Overlay Grad-CAM\n",
    "        ax = axes[1, j]\n",
    "        ax.imshow(img, interpolation=\"bilinear\")\n",
    "        ax.imshow(hm, cmap=\"jet\", alpha=overlay_alpha, interpolation=\"bilinear\")\n",
    "        if show_pred_scores:\n",
    "            ax.set_title(f\"Pred: {class_names[int(preds[j])]}  (p={conf_pred[j]:.2f})\", fontsize=10)\n",
    "        else:\n",
    "            ax.set_title(\"Grad-CAM\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Titres globaux discrets et mise en page\n",
    "    fig.suptitle(\"Illustration Grad-CAM (3 classes)\", fontsize=12)\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "\n",
    "    # Sauvegarde haute résolution pour insertion article\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"[OK] Figure enregistrée : {save_path}\")\n",
    "\n",
    "# ======================\n",
    "# ===== Utilisation =====\n",
    "# ======================\n",
    "# Si tu normalises en ImageNet, passe denorm_mean/std :\n",
    "# plot_gradcam_panel_three_classes(\n",
    "#     cam, test_loader, class_names=CLASS_NAMES,\n",
    "#     save_path=\"gradcam_3classes_panel.png\",\n",
    "#     overlay_alpha=0.45,\n",
    "#     denorm_mean=IMAGENET_MEAN, denorm_std=IMAGENET_STD,\n",
    "#     show_pred_scores=True, dpi=300\n",
    "# )\n",
    "\n",
    "plot_gradcam_panel_three_classes(\n",
    "    cam, test_loader, class_names=CLASS_NAMES,\n",
    "    save_path=\"gradcam_3classes_panel.png\",\n",
    "    overlay_alpha=0.45,\n",
    "    denorm_mean=None, denorm_std=None,  # ← mets tes moyennes/écarts si besoin\n",
    "    show_pred_scores=True, dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Grad-CAM + affichage image originale & superposition heatmap\n",
    "# + extraction ciblée pour la classe \"Normales\"\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# (Optionnel) valeurs ImageNet si tes DataLoaders normalisent en ImageNet\n",
    "# IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# -------------------------\n",
    "# Utils d'affichage/entrée\n",
    "# -------------------------\n",
    "def denormalize(imgs, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    imgs: Tensor (B,3,H,W)\n",
    "    mean, std: tuples len=3. Si None -> pas de denorm.\n",
    "    \"\"\"\n",
    "    imgs = imgs.detach().cpu().float()\n",
    "    if (mean is None) or (std is None):\n",
    "        return imgs.clamp(0, 1)\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "    std  = torch.tensor(std).view(1, 3, 1, 1)\n",
    "    imgs = imgs * std + mean\n",
    "    return imgs.clamp(0, 1)\n",
    "\n",
    "def get_confidence_vector(probs, preds=None):\n",
    "    \"\"\"\n",
    "    probs: (B,C) probabilités softmax.\n",
    "    preds: (B,) classes. Si None -> argmax(probs).\n",
    "    Retour: (B,) confiances associées.\n",
    "    \"\"\"\n",
    "    probs_np = probs.detach().cpu().numpy() if isinstance(probs, torch.Tensor) else np.asarray(probs)\n",
    "    if preds is None:\n",
    "        preds_idx = probs_np.argmax(axis=1)\n",
    "    else:\n",
    "        preds_idx = preds.detach().cpu().numpy() if isinstance(preds, torch.Tensor) else np.asarray(preds)\n",
    "    return probs_np[np.arange(len(probs_np)), preds_idx]\n",
    "\n",
    "def show_gradcam_with_original(\n",
    "    images,\n",
    "    heatmaps,\n",
    "    true_labels=None,\n",
    "    pred_labels=None,\n",
    "    class_names=None,\n",
    "    scores=None,\n",
    "    score_name=\"p\",\n",
    "    cols=4,\n",
    "    denorm_mean=None,\n",
    "    denorm_std=None,\n",
    "    overlay_alpha=0.4\n",
    "):\n",
    "    \"\"\"\n",
    "    Affiche l'image originale + la superposition Grad-CAM côte à côte.\n",
    "    \"\"\"\n",
    "    imgs = images\n",
    "    if imgs.shape[1] == 1:  # grayscale → RGB\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    imgs = denormalize(imgs, mean=denorm_mean, std=denorm_std)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(8 * cols, 4 * rows))  # 2 colonnes (original + overlay)\n",
    "\n",
    "    for i in range(B):\n",
    "        img = np.transpose(imgs[i].numpy(), (1, 2, 0))\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        # Original\n",
    "        ax1 = plt.subplot(rows, cols * 2, 2 * i + 1)\n",
    "        ax1.imshow(img, interpolation='bilinear')\n",
    "        title_left = []\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_left.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        ax1.set_title(\" | \".join(title_left), fontsize=9)\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        # Overlay Grad-CAM\n",
    "        ax2 = plt.subplot(rows, cols * 2, 2 * i + 2)\n",
    "        ax2.imshow(img, interpolation='bilinear')\n",
    "        ax2.imshow(hm, cmap='jet', alpha=overlay_alpha, interpolation='bilinear')\n",
    "        title_right = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_right.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_right.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "        ax2.set_title(\" | \".join(title_right), fontsize=9)\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Trouver une couche cible\n",
    "# -------------------------\n",
    "def find_last_conv_module(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Retourne le dernier nn.Conv2d trouvé en parcourant le modèle.\n",
    "    Utile si tu ne connais pas exactement le chemin (ex: model.cnn.layer4[-1]).\n",
    "    \"\"\"\n",
    "    last_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last_conv = m\n",
    "    if last_conv is None:\n",
    "        raise RuntimeError(\"Aucun nn.Conv2d trouvé dans le modèle pour Grad-CAM.\")\n",
    "    return last_conv\n",
    "\n",
    "# -------------\n",
    "# Grad-CAM core\n",
    "# -------------\n",
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Grad-CAM pour un module convolutionnel cible (target_layer).\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        self.fwd_hook = target_layer.register_forward_hook(self._save_activations)\n",
    "        try:\n",
    "            self.bwd_hook = target_layer.register_full_backward_hook(self._save_gradients)\n",
    "        except Exception:\n",
    "            self.bwd_hook = target_layer.register_backward_hook(self._save_gradients_fallback)\n",
    "\n",
    "    def _save_activations(self, module, input, output):\n",
    "        self.activations = output.detach()  # (B,C,H,W)\n",
    "\n",
    "    def _save_gradients(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()  # (B,C,H,W)\n",
    "\n",
    "    def _save_gradients_fallback(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        try: self.fwd_hook.remove()\n",
    "        except Exception: pass\n",
    "        try: self.bwd_hook.remove()\n",
    "        except Exception: pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _normalize(self, cam):\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "    def __call__(self, images, targets=None, device=None):\n",
    "        \"\"\"\n",
    "        images: (B,3,H,W) ou (B,1,H,W)\n",
    "        targets: (B,) indices de classes. None => classe prédite.\n",
    "        return: heatmaps (B,H,W), preds (B,), probs (B,num_classes)\n",
    "        \"\"\"\n",
    "        device = device or next(self.model.parameters()).device\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = self.model(images)  # (B,C)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        if targets is None:\n",
    "            targets = preds\n",
    "        else:\n",
    "            targets = torch.as_tensor(targets, device=device)\n",
    "\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        selected = outputs.gather(1, targets.view(-1, 1)).sum()\n",
    "        selected.backward()\n",
    "\n",
    "        A = self.activations      # (B,C,H,W)\n",
    "        dA = self.gradients       # (B,C,H,W)\n",
    "        weights = dA.flatten(2).mean(dim=2).view(A.size(0), A.size(1), 1, 1)  # (B,C,1,1)\n",
    "        cam = (weights * A).sum(dim=1)                                        # (B,H,W)\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        heatmaps = torch.stack([self._normalize(cam[i]) for i in range(cam.size(0))], dim=0)\n",
    "        return heatmaps.cpu(), preds.detach().cpu(), probs.detach().cpu()\n",
    "\n",
    "# -----------------------------------------\n",
    "# Récupérer des exemples d'une classe donnée\n",
    "# -----------------------------------------\n",
    "def gather_class_examples(loader, class_id, max_images=8, device=None):\n",
    "    \"\"\"\n",
    "    Parcourt le loader et renvoie jusqu'à max_images images de la classe `class_id`.\n",
    "    \"\"\"\n",
    "    imgs_chunks, labels_chunks = [], []\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        mask = (labels == class_id)\n",
    "        if mask.any():\n",
    "            imgs_chunks.append(images[mask])\n",
    "            labels_chunks.append(labels[mask])\n",
    "            total += int(mask.sum().item())\n",
    "            if total >= max_images:\n",
    "                break\n",
    "    if not imgs_chunks:\n",
    "        raise RuntimeError(f\"Aucune image trouvée pour la classe id={class_id}.\")\n",
    "    imgs = torch.cat(imgs_chunks, dim=0)[:max_images]\n",
    "    labs = torch.cat(labels_chunks, dim=0)[:max_images]\n",
    "    if device is not None:\n",
    "        imgs = imgs.to(device)\n",
    "        labs = labs.to(device)\n",
    "    return imgs, labs\n",
    "\n",
    "# ============================\n",
    "# ======== EXEMPLE ========== #\n",
    "# ============================\n",
    "# Hypothèses: objets existants : model, test_loader, Config (avec DEVICE)\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]  # adapte si besoin\n",
    "\n",
    "device = getattr(Config, \"DEVICE\", next(model.parameters()).device)\n",
    "\n",
    "# 1) Choix de la couche cible: essai direct, sinon auto-détection\n",
    "try:\n",
    "    target_layer = model.cnn.layer4[-1]  # ← adapte au chemin réel de ton modèle\n",
    "except Exception:\n",
    "    target_layer = find_last_conv_module(model)\n",
    "    print(\"[Info] target_layer auto-détecté (dernier Conv2d):\", target_layer.__class__.__name__)\n",
    "\n",
    "# 2) Instancier Grad-CAM\n",
    "cam = GradCAM(model.to(device).eval(), target_layer=target_layer)\n",
    "\n",
    "# 3) Trouver l'ID de la classe \"Normales\" de manière robuste\n",
    "if hasattr(test_loader, \"dataset\") and hasattr(test_loader.dataset, \"class_to_idx\"):\n",
    "    class_to_idx = test_loader.dataset.class_to_idx\n",
    "    normal_name_candidates = [\"Normales\", \"Normal\", \"Normals\"]  # ajoute d'autres variantes si besoin\n",
    "    NORMAL_ID = None\n",
    "    for name in normal_name_candidates:\n",
    "        if name in class_to_idx:\n",
    "            NORMAL_ID = class_to_idx[name]\n",
    "            break\n",
    "    if NORMAL_ID is None:\n",
    "        NORMAL_ID = CLASS_NAMES.index(\"Normales\")  # fallback via CLASS_NAMES\n",
    "else:\n",
    "    NORMAL_ID = CLASS_NAMES.index(\"Normales\")\n",
    "print(f\"[Info] ID 'Normales' = {NORMAL_ID}\")\n",
    "\n",
    "# 4) Extraire des exemples de la classe \"Normales\"\n",
    "try:\n",
    "    normals_images, normals_labels = gather_class_examples(\n",
    "        test_loader, class_id=NORMAL_ID, max_images=8, device=device\n",
    "    )\n",
    "except RuntimeError as e:\n",
    "    print(\"[Alerte]\", e)\n",
    "    normals_images = None\n",
    "\n",
    "# 5) Calcul Grad-CAM et affichage\n",
    "if normals_images is not None:\n",
    "    # Explication par rapport à la vérité (cible = 'Normales')\n",
    "    heatmaps_n, preds_n, probs_n = cam(normals_images, targets=normals_labels, device=device)\n",
    "\n",
    "    # (Option) Pour forcer l'explication sur \"Normales\" même si la prédiction diffère :\n",
    "    # forced_targets = torch.full((normals_images.size(0),), NORMAL_ID, device=device, dtype=torch.long)\n",
    "    # heatmaps_n, preds_n, probs_n = cam(normals_images, targets=forced_targets, device=device)\n",
    "\n",
    "    conf_n = get_confidence_vector(probs_n, preds=preds_n)\n",
    "\n",
    "    show_gradcam_with_original(\n",
    "        images=normals_images,\n",
    "        heatmaps=heatmaps_n,\n",
    "        true_labels=normals_labels.detach().cpu(),\n",
    "        pred_labels=preds_n,\n",
    "        class_names=CLASS_NAMES,\n",
    "        scores=conf_n,\n",
    "        score_name=\"p_pred\",\n",
    "        cols=4,\n",
    "        # denorm_mean=IMAGENET_MEAN,  # décommente si tes images sont normalisées\n",
    "        # denorm_std=IMAGENET_STD,\n",
    "        overlay_alpha=0.4\n",
    "    )\n",
    "\n",
    "# 6) Nettoyer les hooks\n",
    "cam.remove_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Grad-CAM + affichage image originale & superposition heatmap\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# (Optionnel) si tes DataLoaders normalisent en ImageNet :\n",
    "# mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "\n",
    "def denormalize(imgs, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    imgs: Tensor (B,3,H,W) sur CPU ou GPU dans [0,1] normalisé éventuellement.\n",
    "    mean, std: tuples/list len=3. Si None -> pas de denorm.\n",
    "    Retourne un Tensor (B,3,H,W) CPU en [0,1] clampé.\n",
    "    \"\"\"\n",
    "    imgs = imgs.detach().cpu().float()\n",
    "    if (mean is None) or (std is None):\n",
    "        return imgs.clamp(0, 1)\n",
    "\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "    std  = torch.tensor(std).view(1, 3, 1, 1)\n",
    "    imgs = imgs * std + mean\n",
    "    return imgs.clamp(0, 1)\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Grad-CAM classique pour un module convolutionnel cible.\n",
    "    target_layer: nn.Module (ex: model.cnn.layer4[-1] pour ResNet)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        # Hook forward\n",
    "        self.fwd_hook = target_layer.register_forward_hook(self._save_activations)\n",
    "\n",
    "        # Hook backward (full_backward_hook si dispo, sinon fallback)\n",
    "        try:\n",
    "            self.bwd_hook = target_layer.register_full_backward_hook(self._save_gradients)\n",
    "        except Exception:\n",
    "            self.bwd_hook = target_layer.register_backward_hook(self._save_gradients_fallback)\n",
    "\n",
    "    def _save_activations(self, module, input, output):\n",
    "        # output: (B, C, H, W)\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _save_gradients(self, module, grad_input, grad_output):\n",
    "        # grad_output[0]: (B, C, H, W)\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    # Pour compatibilité versions plus anciennes de PyTorch\n",
    "    def _save_gradients_fallback(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        try:\n",
    "            self.fwd_hook.remove()\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            self.bwd_hook.remove()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _normalize(self, cam):\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-8)\n",
    "        return cam\n",
    "\n",
    "    def __call__(self, images, targets=None, device=None):\n",
    "        \"\"\"\n",
    "        images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "        targets: liste/tensor de classes cibles (B,) ou None (=classe prédite)\n",
    "        return: heatmaps (B,H,W) dans [0,1], preds (B,), probs (B,num_classes)\n",
    "        \"\"\"\n",
    "        device = device or next(self.model.parameters()).device\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = self.model(images)  # (B, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        # Cibles de backprop\n",
    "        if targets is None:\n",
    "            targets = preds\n",
    "        else:\n",
    "            targets = torch.as_tensor(targets, device=device)\n",
    "\n",
    "        # Backward sur le logit de la classe cible\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        selected = outputs.gather(1, targets.view(-1, 1)).sum()\n",
    "        selected.backward()\n",
    "\n",
    "        # Activations & gradients -> carte CAM\n",
    "        A = self.activations           # (B,C,H,W)\n",
    "        dA = self.gradients            # (B,C,H,W)\n",
    "\n",
    "        # Poids: moyenne spatiale des gradients\n",
    "        weights = dA.flatten(2).mean(dim=2).view(A.size(0), A.size(1), 1, 1)  # (B,C,1,1)\n",
    "        cam = (weights * A).sum(dim=1)                                        # (B,H,W)\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # Normalisation par image\n",
    "        heatmaps = torch.stack([self._normalize(cam[i]) for i in range(cam.size(0))], dim=0)\n",
    "        return heatmaps.cpu(), preds.detach().cpu(), probs.detach().cpu()\n",
    "\n",
    "def get_confidence_vector(probs, preds=None):\n",
    "    \"\"\"\n",
    "    probs: Tensor/ndarray (B, num_classes) de probabilités (softmax).\n",
    "    preds: Tensor/ndarray (B,) indices de classes. Si None -> argmax(probs).\n",
    "    Retourne: ndarray (B,) des confiances correspondantes.\n",
    "    \"\"\"\n",
    "    if isinstance(probs, torch.Tensor):\n",
    "        probs_np = probs.detach().cpu().numpy()\n",
    "    else:\n",
    "        probs_np = np.asarray(probs)\n",
    "\n",
    "    if preds is None:\n",
    "        preds_idx = probs_np.argmax(axis=1)\n",
    "    else:\n",
    "        preds_idx = preds.detach().cpu().numpy() if isinstance(preds, torch.Tensor) else np.asarray(preds)\n",
    "\n",
    "    return probs_np[np.arange(len(probs_np)), preds_idx]\n",
    "\n",
    "def show_gradcam_with_original(\n",
    "    images,\n",
    "    heatmaps,\n",
    "    true_labels=None,\n",
    "    pred_labels=None,\n",
    "    class_names=None,\n",
    "    scores=None,\n",
    "    score_name=\"p\",\n",
    "    cols=4,\n",
    "    denorm_mean=None,\n",
    "    denorm_std=None,\n",
    "    overlay_alpha=0.4\n",
    "):\n",
    "    \"\"\"\n",
    "    Affiche l'image originale + la superposition Grad-CAM côte à côte.\n",
    "\n",
    "    images: tensor (B,3,H,W) ou (B,1,H,W)\n",
    "    heatmaps: tensor (B,H,W)\n",
    "    true_labels, pred_labels: (B,)\n",
    "    class_names: liste de noms de classes (len = num_classes)\n",
    "    scores: array-like (B,) -> affiché comme score_name=0.987 (ex. proba)\n",
    "    denorm_mean/std: tuples ImageNet si tes images sont normalisées\n",
    "    overlay_alpha: transparence de la heatmap\n",
    "    \"\"\"\n",
    "    imgs = images\n",
    "    if imgs.shape[1] == 1:  # grayscale → RGB\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    # Dé-normalise pour affichage si nécessaire\n",
    "    imgs = denormalize(imgs, mean=denorm_mean, std=denorm_std)\n",
    "\n",
    "    B = imgs.shape[0]\n",
    "    rows = int(np.ceil(B / cols))\n",
    "    plt.figure(figsize=(8 * cols, 4 * rows))  # 2 colonnes par image (original + overlay)\n",
    "\n",
    "    for i in range(B):\n",
    "        img = np.transpose(imgs[i].numpy(), (1, 2, 0))  # (H,W,3), [0,1]\n",
    "        hm = heatmaps[i].numpy()\n",
    "\n",
    "        # --- Colonne 1: Image originale ---\n",
    "        ax1 = plt.subplot(rows, cols * 2, 2 * i + 1)\n",
    "        ax1.imshow(img, interpolation='bilinear')\n",
    "        title_left = []\n",
    "        if true_labels is not None and class_names is not None:\n",
    "            title_left.append(f\"True: {class_names[int(true_labels[i])]}\")\n",
    "        ax1.set_title(\" | \".join(title_left), fontsize=9)\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        # --- Colonne 2: Overlay Grad-CAM ---\n",
    "        ax2 = plt.subplot(rows, cols * 2, 2 * i + 2)\n",
    "        ax2.imshow(img, interpolation='bilinear')\n",
    "        ax2.imshow(hm, cmap='jet', alpha=overlay_alpha, interpolation='bilinear')\n",
    "\n",
    "        title_right = []\n",
    "        if pred_labels is not None and class_names is not None:\n",
    "            title_right.append(f\"Pred: {class_names[int(pred_labels[i])]}\")\n",
    "        if scores is not None:\n",
    "            title_right.append(f\"{score_name}={float(scores[i]):.3f}\")\n",
    "        ax2.set_title(\" | \".join(title_right), fontsize=9)\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ======== EXEMPLE ========== #\n",
    "# ============================\n",
    "\n",
    "# --- Paramètres ---\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]  # adapte à ton mapping\n",
    "device = Config.DEVICE  # suppose que tu as déjà Config.DEVICE défini\n",
    "\n",
    "# --- Choix de la couche cible ---\n",
    "# Ex: ResNet -> le dernier bloc de layer4\n",
    "# Adapte ce chemin selon ton modèle (ex: model.backbone.layer4[-1], etc.)\n",
    "target_layer = model.cnn.layer4[-1]\n",
    "\n",
    "# --- Instancier Grad-CAM ---\n",
    "cam = GradCAM(model.to(device).eval(), target_layer=target_layer)\n",
    "\n",
    "# --- Mini-batch du test pour visualisation ---\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images = batch_images.to(device)\n",
    "batch_labels = batch_labels.to(device)\n",
    "\n",
    "# (Option) choisir les classes cibles = vraies étiquettes pour voir l'explication \"correcte\"\n",
    "# sinon, mets targets=None pour expliquer la classe prédite\n",
    "heatmaps, preds, probs = cam(batch_images, targets=batch_labels, device=device)\n",
    "\n",
    "# Confiance sur la classe prédite (max softmax)\n",
    "conf_pred = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "# --- Afficher: image originale + Grad-CAM ---\n",
    "# Si tes images sont normalisées ImageNet, dé-commente les deux lignes suivantes\n",
    "# IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "show_gradcam_with_original(\n",
    "    images=batch_images,\n",
    "    heatmaps=heatmaps,\n",
    "    true_labels=batch_labels.cpu(),\n",
    "    pred_labels=preds,\n",
    "    class_names=CLASS_NAMES,\n",
    "    scores=conf_pred,\n",
    "    score_name=\"p_pred\",\n",
    "    cols=4,\n",
    "    # denorm_mean=IMAGENET_MEAN,   # ← décommente si besoin\n",
    "    # denorm_std=IMAGENET_STD,     # ← décommente si besoin\n",
    "    overlay_alpha=0.4\n",
    ")\n",
    "\n",
    "# --- Nettoyer les hooks si tu n'en as plus besoin ---\n",
    "cam.remove_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_publication_style(base_fontsize=10):\n",
    "    # Police sans-serif lisible, tailles cohérentes, fond blanc\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"DejaVu Sans\",\n",
    "        \"font.size\": base_fontsize,\n",
    "        \"axes.titlesize\": base_fontsize,\n",
    "        \"axes.labelsize\": base_fontsize,\n",
    "        \"legend.fontsize\": base_fontsize-1,\n",
    "        \"xtick.labelsize\": base_fontsize-1,\n",
    "        \"ytick.labelsize\": base_fontsize-1,\n",
    "        \"figure.dpi\": 100,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.transparent\": False,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    })\n",
    "\n",
    "def set_seed_all(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed);\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_publication_style(10)\n",
    "set_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "def denormalize(img_tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n",
    "    x = img_tensor.detach().cpu().float()\n",
    "    if x.shape[0] == 1:  # grayscale -> pseudo-RGB\n",
    "        x = x.repeat(3,1,1)\n",
    "    m = torch.tensor(mean).view(-1,1,1)\n",
    "    s = torch.tensor(std).view(-1,1,1)\n",
    "    x = (x * s) + m\n",
    "    x = x.clamp(0,1)\n",
    "    return np.transpose(x.numpy(), (1,2,0))\n",
    "\n",
    "def pick_indices_per_class(labels, class_ids, k_per_class=3):\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    idxs = []\n",
    "    for c in class_ids:\n",
    "        pool = np.where(labels == c)[0]\n",
    "        if len(pool) > 0:\n",
    "            k = min(k_per_class, len(pool))\n",
    "            chosen = np.random.choice(pool, size=k, replace=False)\n",
    "            idxs.extend(chosen.tolist())\n",
    "    return idxs\n",
    "\n",
    "def get_confidence_vector(probs, preds=None, targets=None):\n",
    "    probs_np = probs.detach().cpu().numpy()\n",
    "    if preds is not None:\n",
    "        idx = preds.detach().cpu().numpy()\n",
    "    elif targets is not None:\n",
    "        idx = targets.detach().cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Fournir preds OU targets.\")\n",
    "    return probs_np[np.arange(len(probs_np)), idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gradcam_panel(images, heatmaps,\n",
    "                       true_labels=None, pred_labels=None,\n",
    "                       class_names=None, indices=None,\n",
    "                       k_per_class=3, choose_by=\"pred\",\n",
    "                       scores_pred=None,               # proba de la classe prédite (0..1)\n",
    "                       out_path=\"fig_gradcam_test.png\",\n",
    "                       cols=2,\n",
    "                       tile_height_in=2.0, tile_width_in=2.2,  # tuiles + petites\n",
    "                       cmap=\"magma\", alpha=0.45, dpi=300,\n",
    "                       add_colorbar=False):\n",
    "    \"\"\"\n",
    "    Titre court: 'True: X | Pred: Y | conf: 98%'\n",
    "    Images rapprochées (wspace/hspace faibles)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    assert class_names is not None, \"class_names requis.\"\n",
    "    imgs = images.detach().cpu()\n",
    "    hmaps = heatmaps.detach().cpu().numpy() if isinstance(heatmaps, torch.Tensor) else heatmaps\n",
    "\n",
    "    class_ids = np.arange(len(class_names))\n",
    "    # Sélection équilibrée par classe (prédite par défaut)\n",
    "    if indices is None:\n",
    "        base = pred_labels if choose_by == \"pred\" else true_labels\n",
    "        if base is None:\n",
    "            raise ValueError(\"choose_by='pred' nécessite pred_labels, 'true' nécessite true_labels.\")\n",
    "        indices = pick_indices_per_class(base, class_ids, k_per_class=k_per_class)\n",
    "\n",
    "    n = len(indices)\n",
    "    rows = int(np.ceil(n))\n",
    "    fig_w = cols * tile_width_in\n",
    "    fig_h = rows * tile_height_in\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(fig_w, fig_h),\n",
    "                             gridspec_kw={\"wspace\": 0.02, \"hspace\": 0.04})  # images rapprochées\n",
    "    if rows == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    # Boucle\n",
    "    for j, idx in enumerate(indices):\n",
    "        r = j  # une rangée par échantillon (2 colonnes)\n",
    "        img_np = denormalize(imgs[idx])          # image originale\n",
    "        hm     = hmaps[idx]                      # heatmap déjà normalisé\n",
    "\n",
    "        # Noms courts & minuscules\n",
    "        true_txt = class_names[int(true_labels[idx])].lower() if true_labels is not None else \"?\"\n",
    "        pred_txt = class_names[int(pred_labels[idx])].lower() if pred_labels is not None else \"?\"\n",
    "        # Confiance en %\n",
    "        if scores_pred is not None:\n",
    "            conf_pct = int(round(float(scores_pred[idx]) * 100))\n",
    "            conf_txt = f\" | conf: {conf_pct}%\"\n",
    "        else:\n",
    "            conf_txt = \"\"\n",
    "\n",
    "        title_short = f\"True: {true_txt} | Pred: {pred_txt}{conf_txt}\"\n",
    "\n",
    "        # Col 1 : Original\n",
    "        ax1 = axes[r, 0]\n",
    "        ax1.imshow(img_np, interpolation=\"nearest\")\n",
    "        ax1.set_title(title_short, fontsize=8)\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        # Col 2 : Grad-CAM\n",
    "        ax2 = axes[r, 1]\n",
    "        ax2.imshow(img_np, interpolation=\"nearest\")\n",
    "        ax2.imshow(hm, cmap=cmap, alpha=alpha, interpolation=\"bilinear\")\n",
    "        ax2.set_title(\"Grad-CAM\", fontsize=8)\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "    # Sauvegarde serrée\n",
    "    fig.savefig(out_path, dpi=dpi, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.close(fig)\n",
    "    print(f\"🖼️  Figure enregistrée : {out_path} (dpi={dpi})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 0) Style \"publication\"\n",
    "# ============================\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_publication_style(base_fontsize=10):\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"DejaVu Sans\",\n",
    "        \"font.size\": base_fontsize,\n",
    "        \"axes.titlesize\": base_fontsize,\n",
    "        \"axes.labelsize\": base_fontsize,\n",
    "        \"legend.fontsize\": base_fontsize-1,\n",
    "        \"xtick.labelsize\": base_fontsize-1,\n",
    "        \"ytick.labelsize\": base_fontsize-1,\n",
    "        \"figure.dpi\": 100,\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"savefig.transparent\": False,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    })\n",
    "\n",
    "def set_seed_all(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_publication_style(10)\n",
    "set_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1) Helpers (denorm, pick, scores)\n",
    "# ============================\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "def denormalize(img_tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n",
    "    \"\"\"\n",
    "    img_tensor: (C,H,W) torch.Tensor — retourne un numpy (H,W,C) dans [0,1].\n",
    "    \"\"\"\n",
    "    x = img_tensor.detach().cpu().float()\n",
    "    if x.shape[0] == 1:  # grayscale -> pseudo-RGB\n",
    "        x = x.repeat(3,1,1)\n",
    "    m = torch.tensor(mean).view(-1,1,1)\n",
    "    s = torch.tensor(std).view(-1,1,1)\n",
    "    x = (x * s) + m\n",
    "    x = x.clamp(0,1)\n",
    "    return np.transpose(x.numpy(), (1,2,0))\n",
    "\n",
    "def pick_indices_per_class(labels, class_ids, k_per_class=3):\n",
    "    \"\"\"\n",
    "    Retourne jusqu'à k_per_class indices par classe pour une couverture équilibrée.\n",
    "    \"\"\"\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    idxs = []\n",
    "    for c in class_ids:\n",
    "        pool = np.where(labels == c)[0]\n",
    "        if len(pool) > 0:\n",
    "            k = min(k_per_class, len(pool))\n",
    "            chosen = np.random.choice(pool, size=k, replace=False)\n",
    "            idxs.extend(chosen.tolist())\n",
    "    return idxs\n",
    "\n",
    "def get_confidence_vector(probs, preds=None, targets=None):\n",
    "    \"\"\"\n",
    "    probs : torch.Tensor (B, num_classes)\n",
    "    preds : Tensor (B,) classes prédites\n",
    "    targets : Tensor (B,) classes vraies\n",
    "    Retour : np.array (B,) des probabilités correspondantes\n",
    "    \"\"\"\n",
    "    probs_np = probs.detach().cpu().numpy()\n",
    "    if preds is not None:\n",
    "        idx = preds.detach().cpu().numpy()\n",
    "    elif targets is not None:\n",
    "        idx = targets.detach().cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Fournir preds OU targets.\")\n",
    "    return probs_np[np.arange(len(probs_np)), idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gradcam_panel(images, heatmaps,\n",
    "                       true_labels=None, pred_labels=None,\n",
    "                       class_names=None, indices=None,\n",
    "                       k_per_class=3, choose_by=\"pred\",\n",
    "                       scores_pred=None,\n",
    "                       out_path=\"fig_gradcam_test.png\",\n",
    "                       cols=2,\n",
    "                       tile_height_in=1.6, tile_width_in=1.8,  # encore plus compact\n",
    "                       cmap=\"magma\", alpha=0.45, dpi=300):\n",
    "    \"\"\"\n",
    "    Affiche Original | Grad-CAM côte-à-côte.\n",
    "    Texte 'True | Pred | conf' AU-DESSUS de l'image Grad-CAM (taille réduite).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    assert class_names is not None, \"class_names requis.\"\n",
    "    imgs = images.detach().cpu()\n",
    "    hmaps = heatmaps.detach().cpu().numpy() if isinstance(heatmaps, torch.Tensor) else heatmaps\n",
    "\n",
    "    class_ids = np.arange(len(class_names))\n",
    "    if indices is None:\n",
    "        base = pred_labels if choose_by == \"pred\" else true_labels\n",
    "        indices = pick_indices_per_class(base, class_ids, k_per_class=k_per_class)\n",
    "\n",
    "    n = len(indices)\n",
    "    rows = int(np.ceil(n))\n",
    "    fig_w = cols * tile_width_in\n",
    "    fig_h = rows * tile_height_in\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(fig_w, fig_h),\n",
    "                             gridspec_kw={\"wspace\": 0.01, \"hspace\": 0.20})\n",
    "    if rows == 1:\n",
    "        axes = np.array([axes])\n",
    "\n",
    "    for j, idx in enumerate(indices):\n",
    "        r = j\n",
    "        img_np = denormalize(imgs[idx])\n",
    "        hm     = hmaps[idx]\n",
    "\n",
    "        # Texte court\n",
    "        true_txt = class_names[int(true_labels[idx])].lower() if true_labels is not None else \"?\"\n",
    "        pred_txt = class_names[int(pred_labels[idx])].lower() if pred_labels is not None else \"?\"\n",
    "        conf_txt = \"\"\n",
    "        if scores_pred is not None:\n",
    "            conf_pct = int(round(float(scores_pred[idx]) * 100))\n",
    "            conf_txt = f\" | conf: {conf_pct}%\"\n",
    "        title_short = f\"True: {true_txt} | Pred: {pred_txt}{conf_txt}\"\n",
    "\n",
    "        # Col 1 : Original\n",
    "        ax1 = axes[r, 0]\n",
    "        ax1.imshow(img_np, interpolation=\"nearest\")\n",
    "        ax1.set_title(\"Original\", fontsize=6)  # plus petit\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        # Col 2 : Grad-CAM\n",
    "        ax2 = axes[r, 1]\n",
    "        ax2.imshow(img_np, interpolation=\"nearest\")\n",
    "        ax2.imshow(hm, cmap=cmap, alpha=alpha, interpolation=\"bilinear\")\n",
    "        ax2.set_title(title_short, fontsize=6)  # texte compact\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "    fig.savefig(out_path, dpi=dpi, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.close(fig)\n",
    "    print(f\"🖼️  Figure enregistrée : {out_path} (dpi={dpi})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3) Utilisation (PNG 300 dpi + TIFF 600 dpi)\n",
    "# ============================\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "device = Config.DEVICE\n",
    "\n",
    "# 1) Obtenir un batch de test\n",
    "batch_images, batch_labels = next(iter(test_loader))\n",
    "batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
    "\n",
    "# 2) Grad-CAM (cible = classe prédite pour chaque image)\n",
    "#    cam = GradCAM(model.to(device).eval(), target_layer=model.cnn.layer4[-1])  # déjà défini plus haut\n",
    "heatmaps, preds, probs = cam(batch_images, targets=None, device=device)\n",
    "\n",
    "# 3) Score de confiance (classe prédite)\n",
    "conf_pred = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "# 4) Sauvegardes prêtes pour l'article\n",
    "# PNG 300 dpi\n",
    "save_gradcam_panel(batch_images, heatmaps,\n",
    "                   true_labels=batch_labels, pred_labels=preds,\n",
    "                   class_names=CLASS_NAMES,\n",
    "                   k_per_class=3, choose_by=\"pred\",\n",
    "                   scores_pred=conf_pred,\n",
    "                   out_path=\"fig_gradcam_test_compact_smalltext.png\",\n",
    "                   cmap=\"magma\", alpha=0.45, dpi=300)\n",
    "\n",
    "\n",
    "# TIFF 600 dpi (si requis par le journal)\n",
    "save_gradcam_panel(batch_images, heatmaps,\n",
    "                   true_labels=batch_labels, pred_labels=preds,\n",
    "                   class_names=CLASS_NAMES,\n",
    "                   k_per_class=3, choose_by=\"pred\",\n",
    "                   scores_pred=conf_pred,  # <-- pas de scores_true ici\n",
    "                   out_path=\"fig_gradcam_test_600dpi.tif\",\n",
    "                   cmap=\"magma\", alpha=0.45, dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gradcam_samples(model, cam, loader, class_names, k_per_class=3, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Parcourt le loader jusqu'à avoir au moins k_per_class exemples par classe.\n",
    "    Retourne les tenseurs et sélections équilibrées.\n",
    "    \"\"\"\n",
    "    all_images, all_labels, all_heatmaps, all_preds, all_probs = [], [], [], [], []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Grad-CAM\n",
    "        heatmaps, preds, probs = cam(images, targets=None, device=device)\n",
    "\n",
    "        all_images.append(images.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_heatmaps.append(heatmaps)\n",
    "        all_preds.append(preds)\n",
    "        all_probs.append(probs)\n",
    "\n",
    "        # Vérifier si toutes les classes sont couvertes\n",
    "        if len(set(torch.cat(all_labels).numpy())) == len(class_names):\n",
    "            # suffisant pour au moins un exemple par classe\n",
    "            break\n",
    "\n",
    "    # Concaténer\n",
    "    all_images = torch.cat(all_images, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    all_heatmaps = torch.cat(all_heatmaps, dim=0)\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "\n",
    "    # Sélection équilibrée (k par classe)\n",
    "    indices = pick_indices_per_class(all_labels, np.arange(len(class_names)), k_per_class=k_per_class)\n",
    "\n",
    "    return all_images, all_labels, all_heatmaps, all_preds, all_probs, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "\n",
    "# On collecte les images + heatmaps pour toutes les classes\n",
    "imgs, labels, hmaps, preds, probs, idxs = collect_gradcam_samples(\n",
    "    model, cam, test_loader, CLASS_NAMES, k_per_class=3, device=device\n",
    ")\n",
    "\n",
    "# Scores\n",
    "conf_pred = get_confidence_vector(probs, preds=preds)\n",
    "\n",
    "# Affichage équilibré\n",
    "save_gradcam_panel(imgs, hmaps,\n",
    "                   true_labels=labels, pred_labels=preds,\n",
    "                   class_names=CLASS_NAMES,\n",
    "                   indices=idxs,   # <- on force la sélection équilibrée\n",
    "                   scores_pred=conf_pred,\n",
    "                   out_path=\"fig_gradcam_all_classes.png\",\n",
    "                   cmap=\"magma\", alpha=0.45, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def extract_features(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in loader:\n",
    "            images = images.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "\n",
    "            # Forward jusqu’aux features (avant la classification finale)\n",
    "            # ⚠️ Adapter selon ton HybridModel (par ex. model.forward_features)\n",
    "            x = model.cnn(images)          # exemple : CNN backbone\n",
    "            x = torch.flatten(x, 1)        # aplatissement\n",
    "            feats.append(x.cpu())\n",
    "            labels.append(lbls.cpu())\n",
    "\n",
    "    feats = torch.cat(feats, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    return feats, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _to_2d_features(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reçoit un Tensor de features et le convertit en (B, D).\n",
    "    - Si 4D (B,C,H,W) -> GAP + flatten\n",
    "    - Si 2D (B,D)     -> retourne tel quel\n",
    "    - Autre           -> essaie flatten(B, -1)\n",
    "    \"\"\"\n",
    "    if x.dim() == 4:                 # feature map conv\n",
    "        x = F.adaptive_avg_pool2d(x, 1)  # (B,C,1,1)\n",
    "        x = x.flatten(1)                 # (B,C)\n",
    "    elif x.dim() == 2:\n",
    "        pass\n",
    "    else:\n",
    "        x = x.flatten(1)\n",
    "    return x\n",
    "\n",
    "def _pick_tensor_from_output(out):\n",
    "    \"\"\"\n",
    "    Prend une sortie potentiellement complexe (Tensor / list / tuple / dict)\n",
    "    et retourne un Tensor de features raisonnable.\n",
    "    - list/tuple: prend le 1er élément Tensor le plus 'grand'\n",
    "    - dict: essaie clés usuelles ('feat','features','x','out')\n",
    "    - Tensor: retourne tel quel\n",
    "    \"\"\"\n",
    "    if torch.is_tensor(out):\n",
    "        return out\n",
    "    if isinstance(out, (list, tuple)):\n",
    "        # garde le Tensor avec le plus grand nombre d'éléments\n",
    "        tensors = [t for t in out if torch.is_tensor(t)]\n",
    "        if len(tensors) == 0:\n",
    "            raise TypeError(\"La sortie est une liste/tuple sans Tensor.\")\n",
    "        return max(tensors, key=lambda t: t.numel())\n",
    "    if isinstance(out, dict):\n",
    "        for k in (\"feat\", \"features\", \"x\", \"out\"):\n",
    "            if k in out and torch.is_tensor(out[k]):\n",
    "                return out[k]\n",
    "        # sinon, première valeur tensor\n",
    "        for v in out.values():\n",
    "            if torch.is_tensor(v):\n",
    "                return v\n",
    "        raise TypeError(\"Dict de sortie sans Tensor utilisable.\")\n",
    "    raise TypeError(f\"Type de sortie non pris en charge: {type(out)}\")\n",
    "\n",
    "def extract_features(model, loader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Extrait des features (B, D) pour chaque batch du loader.\n",
    "    Essaie model.forward_features(...) si dispo, sinon model.cnn(...).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in loader:\n",
    "            images = images.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "\n",
    "            # 1) chemin 'propre' si dispo\n",
    "            if hasattr(model, \"forward_features\"):\n",
    "                out = model.forward_features(images)\n",
    "            # 2) sinon, tenter le backbone CNN\n",
    "            elif hasattr(model, \"cnn\"):\n",
    "                out = model.cnn(images)\n",
    "            else:\n",
    "                # fallback: utiliser tout le modèle puis récupérer l'avant-dernière couche ?\n",
    "                # Ici, on prend la sortie et on la traite quand même (pas idéal si ce sont des logits)\n",
    "                out = model(images)\n",
    "\n",
    "            # récupérer un Tensor depuis out (gère Tensor/list/tuple/dict)\n",
    "            x = _pick_tensor_from_output(out)\n",
    "            # mettre en (B,D)\n",
    "            x = _to_2d_features(x)\n",
    "\n",
    "            feats.append(x.cpu())\n",
    "            labels.append(lbls.cpu())\n",
    "\n",
    "    feats = torch.cat(feats, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    return feats, labels\n",
    "\n",
    "def compute_tsne(features, labels, class_names, out_path=\"tsne_test.png\",\n",
    "                 perplexity=30, n_iter=1000, random_state=42):\n",
    "    # sécuriser perplexity (doit être < n_samples)\n",
    "    n = features.shape[0]\n",
    "    perp = max(5, min(perplexity, max(5, n//3)))\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, n_iter=n_iter,\n",
    "                init=\"pca\", learning_rate=\"auto\", random_state=random_state)\n",
    "    feats_2d = tsne.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for i, cname in enumerate(class_names):\n",
    "        idxs = labels == i\n",
    "        if np.any(idxs):\n",
    "            plt.scatter(feats_2d[idxs, 0], feats_2d[idxs, 1],\n",
    "                        label=cname, alpha=0.75, s=10)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title(\"t-SNE des représentations (test)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"🖼️  t-SNE enregistré : {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "device = Config.DEVICE\n",
    "\n",
    "features, labels = extract_features(model, test_loader, device=device)\n",
    "compute_tsne(features, labels, CLASS_NAMES, out_path=\"tsne_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP (Uniform Manifold Approximation and Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "def compute_umap(features, labels, class_names,\n",
    "                 n_neighbors=15, min_dist=0.1,\n",
    "                 out_path=\"umap_test.png\", random_state=42):\n",
    "    \"\"\"\n",
    "    Projette les features en 2D avec UMAP et sauvegarde une figure.\n",
    "    \"\"\"\n",
    "    reducer = umap.UMAP(n_components=2,\n",
    "                        n_neighbors=n_neighbors,\n",
    "                        min_dist=min_dist,\n",
    "                        random_state=random_state)\n",
    "    feats_2d = reducer.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for i, cname in enumerate(class_names):\n",
    "        idxs = labels == i\n",
    "        if np.any(idxs):\n",
    "            plt.scatter(feats_2d[idxs, 0], feats_2d[idxs, 1],\n",
    "                        label=cname, alpha=0.75, s=10)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title(\"UMAP des représentations (test)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"🖼️  UMAP enregistré : {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"others\", \"Sickle Cells\", \"Normal\"]\n",
    "\n",
    "# Réutilise les mêmes features extraits pour t-SNE\n",
    "features, labels = extract_features(model, test_loader, device=device)\n",
    "\n",
    "# Visualisation UMAP\n",
    "compute_umap(features, labels, CLASS_NAMES, out_path=\"umap_test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# t-SNE vs UMAP – Comparatif\n",
    "# =========================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    import umap.umap_ as umap\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"UMAP non installé. Fais:  pip install umap-learn\") from e\n",
    "\n",
    "def compute_tsne(features, perplexity=30, n_iter=1000, random_state=42):\n",
    "    n = features.shape[0]\n",
    "    perp = max(5, min(perplexity, max(5, n // 3)))  # sécuriser perplexity\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, n_iter=n_iter,\n",
    "                init=\"pca\", learning_rate=\"auto\", random_state=random_state)\n",
    "    return tsne.fit_transform(features)\n",
    "\n",
    "def compute_umap(features, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors,\n",
    "                        min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(features)\n",
    "\n",
    "def plot_tsne_umap_side_by_side(tsne_2d, umap_2d, labels, class_names,\n",
    "                                title_tsne=\"t-SNE (test)\", title_umap=\"UMAP (test)\",\n",
    "                                out_path_png=\"tsne_umap_comparison.png\",\n",
    "                                out_path_tif=\"tsne_umap_comparison.tif\",\n",
    "                                s=10, alpha=0.75, dpi=300):\n",
    "    \"\"\"\n",
    "    Affiche et sauvegarde une figure 1x2 : t-SNE | UMAP\n",
    "    \"\"\"\n",
    "    # même limites d'axes par méthode (indépendantes) pour un cadrage propre\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9.0, 4.2))\n",
    "    for ax, emb, ttl in zip(axes, [tsne_2d, umap_2d], [title_tsne, title_umap]):\n",
    "        for i, cname in enumerate(class_names):\n",
    "            idxs = (labels == i)\n",
    "            if np.any(idxs):\n",
    "                ax.scatter(emb[idxs, 0], emb[idxs, 1], s=s, alpha=alpha, label=cname)\n",
    "        ax.set_title(ttl)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Légende unique en bas\n",
    "    handles, lbls = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, lbls, loc=\"lower center\", ncol=len(class_names), frameon=False, bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.18)  # place pour la légende\n",
    "    fig.savefig(out_path_png, dpi=dpi, bbox_inches=\"tight\")\n",
    "    fig.savefig(out_path_tif, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"🖼️ Figure enregistrée : {out_path_png} et {out_path_tif} (dpi={dpi})\")\n",
    "\n",
    "# ========= Utilisation =========\n",
    "CLASS_NAMES = [\"Autres\", \"Falciformes\", \"Normales\"]\n",
    "\n",
    "# 1) Réutilise la fonction d’extraction que tu as déjà (features avant la dernière couche)\n",
    "# features, labels = extract_features(model, test_loader, device=Config.DEVICE)\n",
    "\n",
    "# 2) Embeddings\n",
    "tsne_2d = compute_tsne(features, perplexity=30, n_iter=1000, random_state=42)\n",
    "umap_2d = compute_umap(features, n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "\n",
    "# 3) Plot & export (PNG + TIFF, 300 dpi)\n",
    "plot_tsne_umap_side_by_side(tsne_2d, umap_2d, labels, CLASS_NAMES,\n",
    "                            title_tsne=\"t-SNE (Test)\", title_umap=\"UMAP (Test)\",\n",
    "                            out_path_png=\"tsne_umap_comparison.png\",\n",
    "                            out_path_tif=\"tsne_umap_comparison.tif\",\n",
    "                            s=10, alpha=0.75, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Erreurs + Grad-CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def collect_misclassified_with_cam(model, cam, loader, class_names,\n",
    "                                   k_per_class=4, device=\"cuda\",\n",
    "                                   select=\"confident\"):\n",
    "    \"\"\"\n",
    "    Sélectionne des erreurs (par classe vraie), avec Grad-CAM.\n",
    "    select: 'confident' = erreurs à plus forte confiance (classe prédite).\n",
    "    \"\"\"\n",
    "    buckets = {c: [] for c in range(len(class_names))}\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # --- forward classique sans grads pour aller vite\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "        wrong = (preds != labels)\n",
    "\n",
    "        if select == \"confident\":\n",
    "            conf_pred = get_confidence_vector(probs, preds=preds)  # numpy\n",
    "            conf_pred_t = torch.tensor(conf_pred, device=device)\n",
    "            idxs = torch.nonzero(wrong, as_tuple=False).flatten()\n",
    "            if len(idxs) > 0:\n",
    "                order = torch.argsort(conf_pred_t[idxs], descending=True)\n",
    "                idxs = idxs[order]\n",
    "        else:\n",
    "            idxs = torch.nonzero(wrong, as_tuple=False).flatten()\n",
    "\n",
    "        # --- pour chaque erreur sélectionnée: calculer Grad-CAM (avec gradients)\n",
    "        for i in idxs.tolist():\n",
    "            true_c = int(labels[i])\n",
    "            if len(buckets[true_c]) >= k_per_class:\n",
    "                continue\n",
    "\n",
    "            img_i = images[i].unsqueeze(0)\n",
    "\n",
    "            # Très important: réactiver les gradients ici\n",
    "            with torch.enable_grad():\n",
    "                # si tu utilises AMP ailleurs, on le coupe pour le CAM\n",
    "                try:\n",
    "                    from torch.cuda.amp import autocast\n",
    "                    amp_cm = autocast(enabled=False)\n",
    "                except Exception:\n",
    "                    class _Dummy:\n",
    "                        def __enter__(self): pass\n",
    "                        def __exit__(self, *a): pass\n",
    "                    amp_cm = _Dummy()\n",
    "\n",
    "                with amp_cm:\n",
    "                    # Optionnel: s'assurer que les poids peuvent backprop\n",
    "                    for p in model.parameters():\n",
    "                        if p.grad is None and not p.requires_grad:\n",
    "                            p.requires_grad_(True)\n",
    "\n",
    "                    hm_i, pred_i, probs_i = cam(img_i, targets=None, device=device)\n",
    "\n",
    "            pred_i = int(pred_i.item())\n",
    "            prob_pred_i = float(get_confidence_vector(probs_i, preds=torch.tensor([pred_i]))[0])\n",
    "\n",
    "            buckets[true_c].append({\n",
    "                \"image\": images[i].detach().cpu(),\n",
    "                \"label\": int(labels[i]),\n",
    "                \"pred\":  pred_i,\n",
    "                \"prob_pred\": prob_pred_i,\n",
    "                \"heatmap\": hm_i.squeeze(0).detach().cpu()\n",
    "            })\n",
    "\n",
    "        if all(len(buckets[c]) >= k_per_class for c in buckets):\n",
    "            break\n",
    "\n",
    "    # Rassembler\n",
    "    imgs_list, labels_list, preds_list, probs_list, hmaps_list = [], [], [], [], []\n",
    "    for c in range(len(class_names)):\n",
    "        for item in buckets[c]:\n",
    "            imgs_list.append(item[\"image\"])\n",
    "            labels_list.append(item[\"label\"])\n",
    "            preds_list.append(item[\"pred\"])\n",
    "            probs_list.append(item[\"prob_pred\"])\n",
    "            hmaps_list.append(item[\"heatmap\"])\n",
    "\n",
    "    if len(imgs_list) == 0:\n",
    "        print(\"⚠️  Aucune erreur trouvée (ou pas assez dans ce loader).\")\n",
    "        return None\n",
    "\n",
    "    imgs = torch.stack(imgs_list, dim=0)\n",
    "    labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "    preds  = torch.tensor(preds_list,  dtype=torch.long)\n",
    "    probs_pred = torch.tensor(probs_list, dtype=torch.float32)\n",
    "    hmaps = torch.stack(hmaps_list, dim=0)\n",
    "    indices = list(range(len(imgs)))\n",
    "    return imgs, labels, preds, probs_pred, hmaps, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_correct_low_conf_with_cam(model, cam, loader, class_names,\n",
    "                                      k_per_class=4, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Exemples bien classés mais à faible confiance (cas limites).\n",
    "    \"\"\"\n",
    "    buckets = {c: [] for c in range(len(class_names))}\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # --- forward sans grads\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "        conf_pred = get_confidence_vector(probs, preds=preds)  # numpy\n",
    "        conf_pred_t = torch.tensor(conf_pred, device=device)\n",
    "\n",
    "        correct = (preds == labels)\n",
    "        idxs = torch.nonzero(correct, as_tuple=False).flatten()\n",
    "        if len(idxs) > 0:\n",
    "            order = torch.argsort(conf_pred_t[idxs], descending=False)  # faible confiance d'abord\n",
    "            idxs = idxs[order]\n",
    "\n",
    "        for i in idxs.tolist():\n",
    "            true_c = int(labels[i])\n",
    "            if len(buckets[true_c]) >= k_per_class:\n",
    "                continue\n",
    "\n",
    "            img_i = images[i].unsqueeze(0)\n",
    "\n",
    "            # --- Grad-CAM avec gradients\n",
    "            with torch.enable_grad():\n",
    "                try:\n",
    "                    from torch.cuda.amp import autocast\n",
    "                    amp_cm = autocast(enabled=False)\n",
    "                except Exception:\n",
    "                    class _Dummy:\n",
    "                        def __enter__(self): pass\n",
    "                        def __exit__(self, *a): pass\n",
    "                    amp_cm = _Dummy()\n",
    "\n",
    "                with amp_cm:\n",
    "                    for p in model.parameters():\n",
    "                        if p.grad is None and not p.requires_grad:\n",
    "                            p.requires_grad_(True)\n",
    "                    hm_i, pred_i, probs_i = cam(img_i, targets=None, device=device)\n",
    "\n",
    "            pred_i = int(pred_i.item())\n",
    "            prob_pred_i = float(get_confidence_vector(probs_i, preds=torch.tensor([pred_i]))[0])\n",
    "\n",
    "            buckets[true_c].append({\n",
    "                \"image\": images[i].detach().cpu(),\n",
    "                \"label\": int(labels[i]),\n",
    "                \"pred\":  pred_i,\n",
    "                \"prob_pred\": prob_pred_i,\n",
    "                \"heatmap\": hm_i.squeeze(0).detach().cpu()\n",
    "            })\n",
    "\n",
    "        if all(len(buckets[c]) >= k_per_class for c in buckets):\n",
    "            break\n",
    "\n",
    "    imgs_list, labels_list, preds_list, probs_list, hmaps_list = [], [], [], [], []\n",
    "    for c in range(len(class_names)):\n",
    "        for item in buckets[c]:\n",
    "            imgs_list.append(item[\"image\"])\n",
    "            labels_list.append(item[\"label\"])\n",
    "            preds_list.append(item[\"pred\"])\n",
    "            probs_list.append(item[\"prob_pred\"])\n",
    "            hmaps_list.append(item[\"heatmap\"])\n",
    "\n",
    "    if len(imgs_list) == 0:\n",
    "        print(\"⚠️  Pas assez de cas corrects à faible confiance.\")\n",
    "        return None\n",
    "\n",
    "    imgs = torch.stack(imgs_list, dim=0)\n",
    "    labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "    preds  = torch.tensor(preds_list,  dtype=torch.long)\n",
    "    probs_pred = torch.tensor(probs_list, dtype=torch.float32)\n",
    "    hmaps = torch.stack(hmaps_list, dim=0)\n",
    "    indices = list(range(len(imgs)))\n",
    "    return imgs, labels, preds, probs_pred, hmaps, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erreurs haute confiance\n",
    "res_err = collect_misclassified_with_cam(model, cam, test_loader, CLASS_NAMES,\n",
    "                                         k_per_class=3, device=device, select=\"confident\")\n",
    "if res_err is not None:\n",
    "    imgs_e, labels_e, preds_e, conf_e, hmaps_e, idxs_e = res_err\n",
    "    save_gradcam_panel(imgs_e, hmaps_e,\n",
    "                       true_labels=labels_e, pred_labels=preds_e,\n",
    "                       class_names=CLASS_NAMES, indices=idxs_e,\n",
    "                       scores_pred=conf_e,\n",
    "                       out_path=\"errors_high_conf_gradcam.png\",\n",
    "                       cmap=\"magma\", alpha=0.45, dpi=300)\n",
    "\n",
    "# (Optionnel) Corrects faible confiance\n",
    "res_low = collect_correct_low_conf_with_cam(model, cam, test_loader, CLASS_NAMES,\n",
    "                                            k_per_class=3, device=device)\n",
    "if res_low is not None:\n",
    "    imgs_c, labels_c, preds_c, conf_c, hmaps_c, idxs_c = res_low\n",
    "    save_gradcam_panel(imgs_c, hmaps_c,\n",
    "                       true_labels=labels_c, pred_labels=preds_c,\n",
    "                       class_names=CLASS_NAMES, indices=idxs_c,\n",
    "                       scores_pred=conf_c,\n",
    "                       out_path=\"correct_low_conf_gradcam.png\",\n",
    "                       cmap=\"magma\", alpha=0.45, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres, Temps d’inférence pour l’ensemble de données et GFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# ========= 1) Compter les paramètres =========\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "# ========= 2) Mesurer l’inférence sur un DataLoader =========\n",
    "@torch.no_grad()\n",
    "def benchmark_inference(model, loader, device=\"cuda\", amp=False, warmup_batches=5):\n",
    "    \"\"\"\n",
    "    Retourne: dict(total_imgs, total_time_s, imgs_per_s, ms_per_img)\n",
    "    \"\"\"\n",
    "    device_str = str(device)  # <-- conversion\n",
    "    was_training = model.training\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # warmup\n",
    "    it = iter(loader)\n",
    "    for _ in range(min(warmup_batches, len(loader))):\n",
    "        try:\n",
    "            images, _ = next(it)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        if device_str.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16) if (amp and device_str.startswith(\"cuda\")) else nullcontext():\n",
    "            _ = model(images)\n",
    "        if device_str.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "    # mesure\n",
    "    total_imgs = 0\n",
    "    if device_str.startswith(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    for images, _ in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        bs = images.size(0)\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16) if (amp and device_str.startswith(\"cuda\")) else nullcontext():\n",
    "            _ = model(images)\n",
    "        total_imgs += bs\n",
    "\n",
    "    if device_str.startswith(\"cuda\"):\n",
    "        torch.cuda.synchronize()\n",
    "    t_end = time.perf_counter()\n",
    "    total_time = t_end - t_start\n",
    "\n",
    "    imgs_per_s = total_imgs / total_time if total_time > 0 else float(\"inf\")\n",
    "    ms_per_img = (total_time / total_imgs) * 1000.0 if total_imgs > 0 else float(\"inf\")\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return {\n",
    "        \"total_imgs\": total_imgs,\n",
    "        \"total_time_s\": total_time,\n",
    "        \"imgs_per_s\": imgs_per_s,\n",
    "        \"ms_per_img\": ms_per_img,\n",
    "        \"amp_used\": bool(amp),\n",
    "        \"device\": device_str,\n",
    "    }\n",
    "\n",
    "def print_model_runtime_report(model, loader, img_size, device=\"cuda\", amp=False, warmup_batches=5, in_channels=3):\n",
    "    device_str = str(device)  # <-- conversion\n",
    "    H, W = (img_size, img_size) if isinstance(img_size, int) else img_size\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "    print(\"=== PARAMÈTRES ===\")\n",
    "    print(f\"Total params     : {total_params:,}\")\n",
    "    print(f\"Trainable params : {trainable_params:,}\")\n",
    "\n",
    "    stats = benchmark_inference(model, loader, device=device, amp=amp, warmup_batches=warmup_batches)\n",
    "    print(\"\\n=== TEMPS D'INFERENCE (sur DataLoader) ===\")\n",
    "    print(f\"Device           : {stats['device']}  | AMP: {stats['amp_used']}\")\n",
    "    print(f\"Images traitées  : {stats['total_imgs']}\")\n",
    "    print(f\"Temps total      : {stats['total_time_s']:.3f} s\")\n",
    "    print(f\"Throughput       : {stats['imgs_per_s']:.2f} img/s\")\n",
    "    print(f\"Latence moyenne  : {stats['ms_per_img']:.2f} ms / image\")\n",
    "\n",
    "    flops, msg = compute_flops_macs(model, input_shape=(1, in_channels, H, W), device=device)\n",
    "    print(\"\\n=== COMPLEXITÉ (thop) ===\")\n",
    "    if flops is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        print(f\"MACs             : {flops['MACs']:,}  (~{flops['GMACs']:.2f} GMACs)\")\n",
    "        print(f\"GFLOPs (≈2*MACs) : {flops['GFLOPs_approx']:.2f}\")\n",
    "        print(f\"Params (thop)    : {flops['params']:,}\")\n",
    "\n",
    "\n",
    "# ========= 5) Exemple d’utilisation =========\n",
    "# Hypothèses:\n",
    "# - model est déjà chargé et sur Config.DEVICE\n",
    "# - test_loader (ou val_loader) est défini\n",
    "# - Config.IMG_SIZE / Config.IN_CHANNELS existent (sinon remplace par tes valeurs)\n",
    "try:\n",
    "    in_ch = getattr(Config, \"IN_CHANNELS\", 3)\n",
    "    img_sz = getattr(Config, \"IMG_SIZE\", 224)\n",
    "except NameError:\n",
    "    in_ch, img_sz = 3, 224\n",
    "\n",
    "print_model_runtime_report(\n",
    "    model=model,\n",
    "    loader=test_loader,       # ou val_loader\n",
    "    img_size=img_sz,          # ex: 224 ou (224,224)\n",
    "    in_channels=in_ch,        # 1 si grayscale\n",
    "    device=Config.DEVICE,\n",
    "    amp=True,                 # True si tu infères en autocast FP16 sur GPU\n",
    "    warmup_batches=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Params, Throughput, Latence, (G)FLOPs/MACs) en CSV et LaTeX (prêt à coller dans ton article)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_accuracy(model, loader, device=\"cuda\", amp=False):\n",
    "    was_training = model.training\n",
    "    model.eval().to(device)\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    # petite accélération si GPU\n",
    "    use_amp = (amp and str(device).startswith(\"cuda\"))\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        if use_amp:\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                logits = model(images)\n",
    "        else:\n",
    "            logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.numel()\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return 100.0 * correct / max(1, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_model_runtime_metrics(model, loader, img_size, in_channels=3,\n",
    "                                 device=\"cuda\", amp=True, warmup_batches=5):\n",
    "    H, W = (img_size, img_size) if isinstance(img_size, int) else img_size\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "    # Inference bench\n",
    "    stats = benchmark_inference(model, loader, device=device, amp=amp, warmup_batches=warmup_batches)\n",
    "    # FLOPs/MACs (si thop installé)\n",
    "    flops, msg = compute_flops_macs(model, input_shape=(1, in_channels, H, W), device=device)\n",
    "    # Accuracy\n",
    "    acc = evaluate_accuracy(model, loader, device=device, amp=amp)\n",
    "\n",
    "    metrics = {\n",
    "        \"Model\": getattr(model, \"__class__\", type(\"X\",(object,),{})).__name__,\n",
    "        \"ImgSize\": f\"{H}x{W}\",\n",
    "        \"InCh\": in_channels,\n",
    "        \"Device\": str(device),\n",
    "        \"AMP\": bool(stats[\"amp_used\"]),\n",
    "        \"TotalParams\": int(total_params),\n",
    "        \"TrainableParams\": int(trainable_params),\n",
    "        \"Images\": int(stats[\"total_imgs\"]),\n",
    "        \"TotalTime_s\": float(stats[\"total_time_s\"]),\n",
    "        \"Throughput_img_per_s\": float(stats[\"imgs_per_s\"]),\n",
    "        \"Latency_ms_per_img\": float(stats[\"ms_per_img\"]),\n",
    "        \"Accuracy_pct\": float(acc),\n",
    "        \"MACs\": None, \"GMACs\": None, \"GFLOPs_approx\": None,\n",
    "    }\n",
    "    if flops is None:\n",
    "        metrics[\"MACs_msg\"] = msg\n",
    "    else:\n",
    "        metrics[\"MACs\"] = int(flops[\"MACs\"])\n",
    "        metrics[\"GMACs\"] = float(flops[\"GMACs\"])\n",
    "        metrics[\"GFLOPs_approx\"] = float(flops[\"GFLOPs_approx\"])\n",
    "        metrics[\"MACs_msg\"] = \"\"\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from textwrap import dedent\n",
    "\n",
    "def save_metrics_csv(metrics: dict, path=\"runtime_metrics.csv\", round_digits=3):\n",
    "    keys = list(metrics.keys())\n",
    "    # arrondir quelques colonnes numériques pour lisibilité\n",
    "    for k in [\"TotalTime_s\", \"Throughput_img_per_s\", \"Latency_ms_per_img\", \"GMACs\", \"GFLOPs_approx\"]:\n",
    "        if k in metrics and isinstance(metrics[k], (float, int)) and metrics[k] is not None:\n",
    "            metrics[k] = round(float(metrics[k]), round_digits)\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=keys)\n",
    "        w.writeheader()\n",
    "        w.writerow(metrics)\n",
    "    print(f\"📄 CSV écrit: {path}\")\n",
    "\n",
    "def save_metrics_latex(metrics: dict, path=\"runtime_metrics.tex\", caption=\"Résumé des performances d'inférence\", label=\"tab:runtime\"):\n",
    "    # mise en forme avec séparateurs de milliers\n",
    "    def fmt(x, k):\n",
    "        if x is None: return \"--\"\n",
    "        if k in (\"TotalParams\", \"TrainableParams\", \"MACs\"):\n",
    "            return f\"{int(x):,}\".replace(\",\", \" \")\n",
    "        if k in (\"GMACs\", \"GFLOPs_approx\", \"TotalTime_s\", \"Throughput_img_per_s\", \"Latency_ms_per_img\"):\n",
    "            return f\"{float(x):.3f}\"\n",
    "        return str(x)\n",
    "\n",
    "    rows = [\n",
    "        (\"Modèle\",                fmt(metrics[\"Model\"], \"Model\")),\n",
    "        (\"Entrée (HxW, C)\",      f'{metrics[\"ImgSize\"]}, {metrics[\"InCh\"]}'),\n",
    "        (\"Périphérique\",         fmt(metrics[\"Device\"], \"Device\")),\n",
    "        (\"AMP\",                  \"Oui\" if metrics[\"AMP\"] else \"Non\"),\n",
    "        (\"Paramètres (total)\",   fmt(metrics[\"TotalParams\"], \"TotalParams\")),\n",
    "        (\"Paramètres (appr.)\",   fmt(metrics[\"TrainableParams\"], \"TrainableParams\")),\n",
    "        (\"Images évaluées\",      fmt(metrics[\"Images\"], \"Images\")),\n",
    "        (\"Temps total (s)\",      fmt(metrics[\"TotalTime_s\"], \"TotalTime_s\")),\n",
    "        (\"Débit (img/s)\",        fmt(metrics[\"Throughput_img_per_s\"], \"Throughput_img_per_s\")),\n",
    "        (\"Latence (ms/img)\",     fmt(metrics[\"Latency_ms_per_img\"], \"Latency_ms_per_img\")),\n",
    "        (\"MACs\",                 fmt(metrics[\"MACs\"], \"MACs\")),\n",
    "        (\"GMACs\",                fmt(metrics[\"GMACs\"], \"GMACs\")),\n",
    "        (\"GFLOPs (≈2×MACs)\",     fmt(metrics[\"GFLOPs_approx\"], \"GFLOPs_approx\")),\n",
    "    ]\n",
    "\n",
    "    table = dedent(rf\"\"\"\n",
    "    \\begin{{table}}[t]\n",
    "      \\centering\n",
    "      \\caption{{{caption}}}\n",
    "      \\label{{{label}}}\n",
    "      \\begin{{tabular}}{{l r}}\n",
    "        \\toprule\n",
    "        {\" \\\\\\\\\".join([f\"{k} & {v}\" for k,v in rows])} \\\\\\\\\n",
    "        \\bottomrule\n",
    "      \\end{{tabular}}\n",
    "    \\end{{table}}\n",
    "    \"\"\").strip()\n",
    "\n",
    "    # ajouter les packages si tu les utilises (booktabs)\n",
    "    preamble_hint = \"% Requiert \\\\usepackage{booktabs}\\n\"\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(preamble_hint + table + \"\\n\")\n",
    "    print(f\"📝 LaTeX écrit: {path}  (n'oublie pas \\\\usepackage{{booktabs}})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définis in_ch et img_sz selon ta Config\n",
    "try:\n",
    "    in_ch = getattr(Config, \"IN_CHANNELS\", 3)\n",
    "    img_sz = getattr(Config, \"IMG_SIZE\", 224)\n",
    "except NameError:\n",
    "    in_ch, img_sz = 3, 224\n",
    "\n",
    "metrics = gather_model_runtime_metrics(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    img_size=img_sz,\n",
    "    in_channels=in_ch,\n",
    "    device=Config.DEVICE,  # torch.device OK\n",
    "    amp=True,              # mets False si tu ne veux pas d'autocast\n",
    "    warmup_batches=5\n",
    ")\n",
    "\n",
    "save_metrics_csv(metrics, path=\"runtime_metrics.csv\")\n",
    "save_metrics_latex(metrics, path=\"runtime_metrics.tex\",\n",
    "                   caption=\"Paramètres, temps d'inférence sur le test et complexité (MACs/GFLOPs).\",\n",
    "                   label=\"tab:runtime_overview\")\n",
    "\n",
    "# (Option) affichage rapide\n",
    "from pprint import pprint\n",
    "pprint(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "def benchmark_split(model, loader, device=\"cuda\", amp=True, warmup_batches=5):\n",
    "    model.eval()\n",
    "    iters, n_imgs, t0 = 0, 0, 0.0\n",
    "    amp_ctx = torch.amp.autocast(\"cuda\") if (amp and device.startswith(\"cuda\")) else nullcontext()\n",
    "    # --- warmup ---\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(loader):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            with amp_ctx:\n",
    "                _ = model(x)\n",
    "            iters += 1; n_imgs += x.size(0)\n",
    "            if iters >= warmup_batches: break\n",
    "    if device.startswith(\"cuda\"): torch.cuda.synchronize()\n",
    "    # --- timed pass ---\n",
    "    n_imgs = 0\n",
    "    t_start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            with amp_ctx:\n",
    "                _ = model(x)\n",
    "    if device.startswith(\"cuda\"): torch.cuda.synchronize()\n",
    "    t_end = time.perf_counter()\n",
    "\n",
    "    total_time = t_end - t_start\n",
    "    total_imgs = len(loader.dataset)\n",
    "    throughput = total_imgs / total_time\n",
    "    latency_ms = 1000.0 / throughput\n",
    "    return {\"Images\": total_imgs, \"TotalTime_s\": total_time,\n",
    "            \"Throughput_img_per_s\": throughput, \"Latency_ms_per_img\": latency_ms}\n",
    "\n",
    "# Exemple :\n",
    "train_stats = benchmark_split(model, train_loader, device=\"cuda\", amp=True)\n",
    "val_stats   = benchmark_split(model, val_loader,   device=\"cuda\", amp=True)\n",
    "test_stats  = benchmark_split(model, test_loader,  device=\"cuda\", amp=True)\n",
    "print(train_stats, val_stats, test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== Données (édite ici) ====\n",
    "model_name = \"HybridModel (DrepaViT)\"\n",
    "hardware    = \"Intel Core i5-8365U • 8GB RAM\"\n",
    "input_shape = \"224×224×3\"\n",
    "\n",
    "params_total = 26_389_827         # paramètres\n",
    "gflops_per_img = 9.221            # GFLOPs / image\n",
    "gmacs_per_img  = 4.611            # GMACs / image\n",
    "\n",
    "times_sec = {                      # temps totaux (secondes)\n",
    "    \"Train (N=2024)\": 12.168114131000038,\n",
    "    \"Validation (N=577)\": 1.9403658350001933,\n",
    "    \"Test (N=324)\": 1.282117255999765,\n",
    "}\n",
    "throughput = {                     # img/s\n",
    "    \"Train (N=2024)\": 166.33637539966574,\n",
    "    \"Validation (N=577)\": 297.3666045815234,\n",
    "    \"Test (N=324)\": 252.7069957789098,\n",
    "}\n",
    "latency_ms = {                     # ms / image\n",
    "    \"Train (N=2024)\": 6.011914096343893,\n",
    "    \"Validation (N=577)\": 3.3628524003469558,\n",
    "    \"Test (N=324)\": 3.9571520246906324,\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 11})\n",
    "\n",
    "def annotate(bars, fmt=\"{:.2f}\", suffix=\"\", fontsize=10):\n",
    "    for r in bars:\n",
    "        h = r.get_height()\n",
    "        plt.text(r.get_x()+r.get_width()/2, h, fmt.format(h)+suffix,\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=fontsize)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12.5, 4.2))\n",
    "\n",
    "# (a) Complexité\n",
    "ax = axes[0]\n",
    "labels_a = [\"Parameters (M)\", \"GFLOPs / img\", \"GMACs / img\"]\n",
    "vals_a   = [params_total/1e6, gflops_per_img, gmacs_per_img]\n",
    "bars = ax.bar(labels_a, vals_a)\n",
    "annotate(bars, \"{:.2f}\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"(a) Model Complexity — \" + model_name)\n",
    "ax.tick_params(axis=\"x\", rotation=12)\n",
    "\n",
    "# (b) Temps d'inférence\n",
    "ax = axes[1]\n",
    "labels_b = list(times_sec.keys())\n",
    "vals_b   = [times_sec[k] for k in labels_b]\n",
    "bars = ax.bar(labels_b, vals_b)\n",
    "annotate(bars, \"{:.2f}\", \"s\")\n",
    "ax.set_ylabel(\"Total time (s)\")\n",
    "ax.set_title(\"(b) Inference Time per Split\")\n",
    "ax.tick_params(axis=\"x\", rotation=12)\n",
    "\n",
    "# Petite légende texte (débit/latence)\n",
    "cap = (f\"Throughput / Latency — \"\n",
    "       f\"Train: {throughput[labels_b[0]]:.1f} img/s; {latency_ms[labels_b[0]]:.2f} ms  |  \"\n",
    "       f\"Val: {throughput[labels_b[1]]:.1f}; {latency_ms[labels_b[1]]:.2f} ms  |  \"\n",
    "       f\"Test: {throughput[labels_b[2]]:.1f}; {latency_ms[labels_b[2]]:.2f} ms\")\n",
    "fig.suptitle(f\"{model_name}  •  Input {input_shape}  •  {hardware}\", y=1.03, fontsize=12)\n",
    "fig.text(0.5, 0.01, cap, ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.04, 1, 0.98])\n",
    "plt.savefig(\"fig_drepavit_complexity_ab.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== Réglages taille & résolution =====\n",
    "FIG_W, FIG_H = 8, 5.2    # ← augmente FIG_W pour allonger la figure\n",
    "SAVE_DPI     = 450        # résolution export\n",
    "FONT_SIZE    = 11\n",
    "plt.rcParams.update({\"font.size\": FONT_SIZE})\n",
    "\n",
    "# ===== Données (édite si besoin) =====\n",
    "model_name  = \"HybridModel (DrepaViT)\"\n",
    "hardware    = \"Intel Core i5-8365U • 8GB RAM\"\n",
    "input_shape = \"224×224×3\"\n",
    "\n",
    "params_total   = 26_389_827         # paramètres absolus\n",
    "gflops_per_img = 9.221              # GFLOPs / image\n",
    "gmacs_per_img  = 4.611              # GMACs / image\n",
    "\n",
    "times_sec = {                        # temps totaux (secondes)\n",
    "    \"Train (N=2024)\": 12.168114131000038,\n",
    "    \"Validation (N=577)\": 1.9403658350001933,\n",
    "    \"Test (N=324)\": 1.282117255999765,\n",
    "}\n",
    "throughput = {                       # img/s\n",
    "    \"Train (N=2024)\": 166.33637539966574,\n",
    "    \"Validation (N=577)\": 297.3666045815234,\n",
    "    \"Test (N=324)\": 252.7069957789098,\n",
    "}\n",
    "latency_ms = {                       # ms / image\n",
    "    \"Train (N=2024)\": 6.011914096343893,\n",
    "    \"Validation (N=577)\": 3.3628524003469558,\n",
    "    \"Test (N=324)\": 3.9571520246906324,\n",
    "}\n",
    "\n",
    "# ===== Palettes (couleurs distinctes) =====\n",
    "palette_a = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]   # (a) Params / GFLOPs / GMACs\n",
    "palette_b = [\"#4c72b0\", \"#dd8452\", \"#55a868\"]   # (b) Train / Val / Test\n",
    "\n",
    "# ===== Utilitaires =====\n",
    "def annotate_fallback(ax, bars, labels, pad_frac=0.06, fontsize=9):\n",
    "    \"\"\"Annoter au-dessus des barres si Matplotlib<3.4 (sans bar_label).\"\"\"\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    span = ymax - ymin\n",
    "    for r, txt in zip(bars, labels):\n",
    "        h = r.get_height()\n",
    "        ax.text(r.get_x() + r.get_width()/2, h + pad_frac*span, txt,\n",
    "                ha=\"center\", va=\"bottom\", fontsize=fontsize, clip_on=False)\n",
    "\n",
    "# ===== Figure =====\n",
    "fig, axes = plt.subplots(1, 2, figsize=(FIG_W, FIG_H))\n",
    "# Réserver de la place pour le supertitre et la légende bas\n",
    "fig.subplots_adjust(top=0.86, bottom=0.26, wspace=0.30)\n",
    "\n",
    "# ---------- (a) Complexité ----------\n",
    "ax = axes[0]\n",
    "labels_a = [\"Parameters (M)\", \"GFLOPs / img\", \"GMACs / img\"]\n",
    "vals_a   = [params_total/1e6, gflops_per_img, gmacs_per_img]\n",
    "bars_a   = ax.bar(labels_a, vals_a, color=palette_a)\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"(a) Model Complexity — \" + model_name)\n",
    "ax.tick_params(axis=\"x\", rotation=12)\n",
    "ax.set_ylim(0, max(vals_a) * 1.40)  # headroom pour les labels\n",
    "ax.margins(x=0.06)\n",
    "\n",
    "# Labels au-dessus des barres\n",
    "labels_text_a = [f\"{v:.2f}\" for v in vals_a]\n",
    "if hasattr(ax, \"bar_label\"):\n",
    "    ax.bar_label(bars_a, labels=labels_text_a, label_type=\"edge\", padding=4, fontsize=9)\n",
    "else:\n",
    "    annotate_fallback(ax, bars_a, labels_text_a, pad_frac=0.08, fontsize=9)\n",
    "\n",
    "# ---------- (b) Temps d'inférence ----------\n",
    "ax = axes[1]\n",
    "labels_b = list(times_sec.keys())\n",
    "vals_b   = [times_sec[k] for k in labels_b]\n",
    "bars_b   = ax.bar(labels_b, vals_b, color=palette_b)\n",
    "ax.set_ylabel(\"Total time (s)\")\n",
    "ax.set_title(\"(b) Inference Time per Split\")\n",
    "ax.tick_params(axis=\"x\", rotation=20)\n",
    "ax.set_ylim(0, max(vals_b) * 1.40)  # headroom\n",
    "ax.margins(x=0.08)\n",
    "\n",
    "labels_text_b = [f\"{v:.2f}s\" for v in vals_b]\n",
    "if hasattr(ax, \"bar_label\"):\n",
    "    ax.bar_label(bars_b, labels=labels_text_b, label_type=\"edge\", padding=4, fontsize=9)\n",
    "else:\n",
    "    annotate_fallback(ax, bars_b, labels_text_b, pad_frac=0.08, fontsize=9)\n",
    "\n",
    "# ---------- Supertitre & légende bas ----------\n",
    "fig.suptitle(f\"{model_name}  •  Input {input_shape}  •  {hardware}\",\n",
    "             y=0.92, fontsize=12)\n",
    "\n",
    "cap = (f\"Throughput / Latency — \"\n",
    "       f\"Train: {throughput[labels_b[0]]:.1f} img/s; {latency_ms[labels_b[0]]:.2f} ms  |  \"\n",
    "       f\"Val: {throughput[labels_b[1]]:.1f} img/s; {latency_ms[labels_b[1]]:.2f} ms  |  \"\n",
    "       f\"Test: {throughput[labels_b[2]]:.1f} img/s; {latency_ms[labels_b[2]]:.2f} ms\")\n",
    "fig.text(0.5, 0.08, cap, ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "# ---------- Export ----------\n",
    "plt.tight_layout(rect=[0, 0.14, 1, 0.88])\n",
    "plt.savefig(\"fig_drepavit_complexity_ab_colored_vfinal.png\",\n",
    "            dpi=SAVE_DPI, bbox_inches=\"tight\", pad_inches=0.35)\n",
    "plt.savefig(\"fig_drepavit_complexity_ab_colored_vfinal.pdf\",\n",
    "            dpi=SAVE_DPI, bbox_inches=\"tight\", pad_inches=0.35)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparaison avec plusieurs modèles (Baseline CNN vs HybridModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_multiple_models(models, loaders, img_size, in_channels=3, device=\"cuda\", amp=True, warmup_batches=5):\n",
    "    \"\"\"\n",
    "    models : dict { \"Nom\": model_obj }\n",
    "    loaders: dict { \"Nom\": loader }  (si tu veux loader spécifique par modèle, sinon passe le même partout)\n",
    "    Retourne: list[dict] (une ligne de métriques par modèle)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        loader = loaders.get(name, list(loaders.values())[0])  # prend le premier loader si pas précisé\n",
    "        print(f\"\\n🔎 Benchmark du modèle: {name}\")\n",
    "        m = gather_model_runtime_metrics(model, loader,\n",
    "                                         img_size=img_size,\n",
    "                                         in_channels=in_channels,\n",
    "                                         device=device,\n",
    "                                         amp=amp,\n",
    "                                         warmup_batches=warmup_batches)\n",
    "        m[\"Model\"] = name  # forcer nom lisible\n",
    "        results.append(m)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_multi_csv(results, path=\"runtime_metrics_multi.csv\", round_digits=3):\n",
    "    if not results:\n",
    "        return\n",
    "    keys = list(results[0].keys())\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=keys)\n",
    "        w.writeheader()\n",
    "        for r in results:\n",
    "            row = r.copy()\n",
    "            for k in [\"TotalTime_s\", \"Throughput_img_per_s\", \"Latency_ms_per_img\", \"GMACs\", \"GFLOPs_approx\"]:\n",
    "                if k in row and isinstance(row[k], (float, int)) and row[k] is not None:\n",
    "                    row[k] = round(float(row[k]), round_digits)\n",
    "            w.writerow(row)\n",
    "    print(f\"📄 CSV comparatif écrit: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_multi_latex(results, path=\"runtime_metrics_multi.tex\",\n",
    "                             caption=\"Comparaison des modèles sur temps d'inférence et complexité\",\n",
    "                             label=\"tab:runtime_multi\"):\n",
    "    if not results:\n",
    "        return\n",
    "\n",
    "    headers = [\"Modèle\", \"Params\", \"Débit (img/s)\", \"Latence (ms)\", \"GMACs\", \"GFLOPs\"]\n",
    "    lines = []\n",
    "    for r in results:\n",
    "        params = f\"{int(r['TotalParams']):,}\".replace(\",\", \" \")\n",
    "        thr = f\"{r['Throughput_img_per_s']:.2f}\"\n",
    "        lat = f\"{r['Latency_ms_per_img']:.2f}\"\n",
    "        gmacs = f\"{r['GMACs']:.2f}\" if r[\"GMACs\"] is not None else \"--\"\n",
    "        gflops = f\"{r['GFLOPs_approx']:.2f}\" if r[\"GFLOPs_approx\"] is not None else \"--\"\n",
    "        lines.append(f\"{r['Model']} & {params} & {thr} & {lat} & {gmacs} & {gflops} \\\\\\\\\")\n",
    "\n",
    "    table = dedent(rf\"\"\"\n",
    "    \\begin{{table}}[t]\n",
    "      \\centering\n",
    "      \\caption{{{caption}}}\n",
    "      \\label{{{label}}}\n",
    "      \\begin{{tabular}}{{l r r r r r}}\n",
    "        \\toprule\n",
    "        {' & '.join(headers)} \\\\\\\\\n",
    "        \\midrule\n",
    "        {'\\n'.join(lines)}\n",
    "        \\bottomrule\n",
    "      \\end{{tabular}}\n",
    "    \\end{{table}}\n",
    "    \"\"\").strip()\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"% Requiert \\\\usepackage{booktabs}\\n\")\n",
    "        f.write(table + \"\\n\")\n",
    "    print(f\"📝 LaTeX comparatif écrit: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose que tu as deux modèles: baseline CNN et ton HybridModel\n",
    "models = {\n",
    "    \"BaselineCNN\": baseline_model,\n",
    "    \"HybridModel\": model\n",
    "}\n",
    "\n",
    "# Si un seul loader pour tous (test_loader par ex.)\n",
    "loaders = { \"BaselineCNN\": test_loader, \"HybridModel\": test_loader }\n",
    "\n",
    "results = gather_multiple_models(models, loaders,\n",
    "                                 img_size=img_sz,\n",
    "                                 in_channels=in_ch,\n",
    "                                 device=Config.DEVICE,\n",
    "                                 amp=True,\n",
    "                                 warmup_batches=5)\n",
    "\n",
    "save_metrics_multi_csv(results, path=\"runtime_metrics_multi.csv\")\n",
    "save_metrics_multi_latex(results, path=\"runtime_metrics_multi.tex\",\n",
    "                         caption=\"Comparaison Baseline CNN vs HybridModel sur le test\",\n",
    "                         label=\"tab:runtime_comparison\")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Tes chiffres DrepaViT (tu peux ajuster ici) ======\n",
    "drepavit = {\n",
    "    \"name\": \"DrepaViT@224\",\n",
    "    \"acc\": 0.99,\n",
    "    \"precision\": 0.9872,\n",
    "    \"recall\": 0.9864,          # = sensibilité\n",
    "    \"f1\": 0.9867,\n",
    "    \"specificity\": 0.9938,\n",
    "    \"mcc\": 0.9807,\n",
    "    \"auc\": 0.9996,\n",
    "    \"params\": 26_389_827,\n",
    "    \"gflops\": 9.288,\n",
    "}\n",
    "\n",
    "# ====== (A) Figure GFLOPs par modèle (avec DrepaViT ajouté) ======\n",
    "models = [\n",
    "    (\"MobileNetV2@224\",      2_261_827,   0.613),\n",
    "    (\"VGG16@224\",          134_272_835,  30.952),\n",
    "    (\"VGG19@224\",          139_582_531,  39.277),\n",
    "    (\"ResNet50@224\",        23_593_859,   7.751),\n",
    "    (\"EfficientNetB0@224\",   4_053_414,   0.800),\n",
    "    (\"InceptionV3@299\",     21_808_931,  11.465),\n",
    "    (\"Xception@299\",        20_867_627,  16.770),\n",
    "    (drepavit[\"name\"],       drepavit[\"params\"], drepavit[\"gflops\"]),  # DrepaViT ajouté\n",
    "]\n",
    "\n",
    "# tri croissant par GFLOPs\n",
    "models_sorted = sorted(models, key=lambda x: x[2])\n",
    "names   = [m[0] for m in models_sorted]\n",
    "paramsM = [m[1] / 1e6 for m in models_sorted]\n",
    "gflops  = [m[2] for m in models_sorted]\n",
    "\n",
    "labels = [f\"{n} ({p:.1f}M)\" for n, p in zip(names, paramsM)]\n",
    "palette = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\n",
    "           \"#9467bd\",\"#8c564b\",\"#e377c2\",\"#17becf\",\"#7f7f7f\"]\n",
    "colors  = [palette[i % len(palette)] for i in range(len(labels))]\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 11})\n",
    "plt.figure(figsize=(13.5, 6))\n",
    "ypos = range(len(labels))\n",
    "bars = plt.barh(ypos, gflops, color=colors)\n",
    "\n",
    "for y, v in zip(ypos, gflops):\n",
    "    plt.text(v, y, f\"  {v:.3f}\", va=\"center\", ha=\"left\", fontsize=10)\n",
    "\n",
    "plt.yticks(ypos, labels)\n",
    "plt.xlabel(\"GFLOPs / image (224×224 ; 299×299 indiqué)\")\n",
    "plt.title(\"Comparaison des GFLOPs par modèle (incluant DrepaViT)\")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_sota_gflops_with_drepavit.png\", dpi=450, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# ====== (B) Figure métriques DrepaViT (barres) ======\n",
    "metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\", \"MCC\", \"AUC\"]\n",
    "metric_vals  = [drepavit[\"acc\"], drepavit[\"precision\"], drepavit[\"recall\"],\n",
    "                drepavit[\"f1\"], drepavit[\"specificity\"], drepavit[\"mcc\"], drepavit[\"auc\"]]\n",
    "metric_pct   = [100*x for x in metric_vals]\n",
    "\n",
    "plt.figure(figsize=(11, 4.8))\n",
    "bars = plt.bar(metric_names, metric_pct, color=[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\n",
    "                                                \"#9467bd\",\"#8c564b\",\"#17becf\"])\n",
    "try:\n",
    "    # labels au-dessus\n",
    "    plt.gca().bar_label(bars, labels=[f\"{v:.2f}%\" for v in metric_pct],\n",
    "                        label_type=\"edge\", padding=3, fontsize=9)\n",
    "except Exception:\n",
    "    ymax = max(metric_pct) * 1.2\n",
    "    plt.ylim(0, ymax)\n",
    "    for r, txt in zip(bars, [f\"{v:.2f}%\" for v in metric_pct]):\n",
    "        h = r.get_height()\n",
    "        plt.text(r.get_x()+r.get_width()/2, h + 0.02*ymax, txt,\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.ylabel(\"Score (%)\")\n",
    "plt.title(\"DrepaViT — Métriques sur l'ensemble évalué\")\n",
    "plt.ylim(0, 105)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_drepavit_metrics_bar.png\", dpi=450, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# ====== (C) Mini-card Params & GFLOPs (2 barres) ======\n",
    "plt.figure(figsize=(6.8, 4.2))\n",
    "labels = [\"Parameters (M)\", \"GFLOPs / image\"]\n",
    "values = [drepavit[\"params\"]/1e6, drepavit[\"gflops\"]]\n",
    "bars = plt.bar(labels, values, color=[\"#1f77b4\", \"#ff7f0e\"])\n",
    "\n",
    "try:\n",
    "    plt.gca().bar_label(bars, labels=[f\"{values[0]:.2f}M\", f\"{values[1]:.3f}\"],\n",
    "                        label_type=\"edge\", padding=4, fontsize=10)\n",
    "except Exception:\n",
    "    ymax = max(values) * 1.35\n",
    "    plt.ylim(0, ymax)\n",
    "    for r, txt in zip(bars, [f\"{values[0]:.2f}M\", f\"{values[1]:.3f}\"]):\n",
    "        h = r.get_height()\n",
    "        plt.text(r.get_x()+r.get_width()/2, h + 0.03*ymax, txt,\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"DrepaViT — Parameters & GFLOPs @224×224\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_drepavit_params_gflops.png\", dpi=450, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Figure composite (a/b/c) : SOTA GFLOPs + métriques DrepaViT + Params/GFLOPs DrepaViT ===\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# 0) Données à personnaliser\n",
    "# -----------------------\n",
    "# SOTA + DrepaViT (GFLOPs)\n",
    "models = [\n",
    "    (\"MobileNetV2@224\",        2_261_827,   0.613),\n",
    "    (\"VGG16@224\",            134_272_835,  30.952),\n",
    "    (\"VGG19@224\",            139_582_531,  39.277),\n",
    "    (\"ResNet50@224\",          23_593_859,   7.751),\n",
    "    (\"EfficientNetB0@224\",     4_053_414,   0.800),\n",
    "    (\"InceptionV3@299\",       21_808_931,  11.465),\n",
    "    (\"Xception@299\",          20_867_627,  16.770),\n",
    "    (\"DrepaViT@224 (proposé)\", 26_389_827,   9.288),  # DrepaViT inséré\n",
    "]\n",
    "\n",
    "# Métriques DrepaViT (valeurs 0..1)\n",
    "drepavit = {\n",
    "    \"name\": \"DrepaViT\",\n",
    "    \"acc\": 0.99,\n",
    "    \"precision\": 0.9872,\n",
    "    \"recall\": 0.9864,          # Sensibilité\n",
    "    \"f1\": 0.9867,\n",
    "    \"specificity\": 0.9938,\n",
    "    \"mcc\": 0.9807,\n",
    "    \"auc\": 0.9996,\n",
    "    \"params\": 26_389_827,\n",
    "    \"gflops\": 9.288,\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# 1) Panneau (a) : GFLOPs par modèle (barres horizontales)\n",
    "# -----------------------\n",
    "def panel_a(path=\"panel_a_gflops.png\", dpi=450):\n",
    "    models_sorted = sorted(models, key=lambda x: x[2])\n",
    "    names   = [m[0] for m in models_sorted]\n",
    "    paramsM = [m[1] / 1e6 for m in models_sorted]\n",
    "    gflops  = [m[2] for m in models_sorted]\n",
    "    labels  = [f\"{n} ({p:.1f}M)\" for n, p in zip(names, paramsM)]\n",
    "\n",
    "    # Palette simple (couleurs distinctes)\n",
    "    palette = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\n",
    "               \"#9467bd\",\"#8c564b\",\"#e377c2\",\"#17becf\",\"#7f7f7f\"]\n",
    "    colors = [palette[i % len(palette)] for i in range(len(labels))]\n",
    "\n",
    "    plt.rcParams.update({\"font.size\": 11})\n",
    "    fig_h = 6 + 0.25 * max(0, len(labels) - 7)\n",
    "    plt.figure(figsize=(13.0, fig_h))\n",
    "    ypos = range(len(labels))\n",
    "    bars = plt.barh(ypos, gflops, color=colors)\n",
    "\n",
    "    # Annotations au bout des barres\n",
    "    for y, v in zip(ypos, gflops):\n",
    "        plt.text(v, y, f\"  {v:.3f}\", va=\"center\", ha=\"left\", fontsize=10)\n",
    "\n",
    "    plt.yticks(ypos, labels)\n",
    "    plt.xlabel(\"GFLOPs / image (224×224 ; 299×299 indiqué)\")\n",
    "    plt.title(\"(a) GFLOPs par modèle (incluant DrepaViT)\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "# -----------------------\n",
    "# 2) Panneau (b) : Métriques DrepaViT (barres)\n",
    "# -----------------------\n",
    "def panel_b(path=\"panel_b_metrics.png\", dpi=450):\n",
    "    metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\", \"MCC\", \"AUC\"]\n",
    "    metric_vals  = [drepavit[\"acc\"], drepavit[\"precision\"], drepavit[\"recall\"],\n",
    "                    drepavit[\"f1\"], drepavit[\"specificity\"], drepavit[\"mcc\"], drepavit[\"auc\"]]\n",
    "    metric_pct   = [100*x for x in metric_vals]\n",
    "\n",
    "    plt.rcParams.update({\"font.size\": 11})\n",
    "    plt.figure(figsize=(11.5, 4.6))\n",
    "    bars = plt.bar(metric_names, metric_pct,\n",
    "                   color=[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\n",
    "                          \"#9467bd\",\"#8c564b\",\"#17becf\"])\n",
    "    # Labels au-dessus\n",
    "    try:\n",
    "        plt.gca().bar_label(bars, labels=[f\"{v:.2f}%\" for v in metric_pct],\n",
    "                            label_type=\"edge\", padding=3, fontsize=9)\n",
    "    except Exception:\n",
    "        ymax = max(metric_pct) * 1.2\n",
    "        plt.ylim(0, ymax)\n",
    "        for r, txt in zip(bars, [f\"{v:.2f}%\" for v in metric_pct]):\n",
    "            h = r.get_height()\n",
    "            plt.text(r.get_x()+r.get_width()/2, h + 0.02*ymax, txt,\n",
    "                     ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    plt.ylabel(\"Score (%)\")\n",
    "    plt.title(\"(b) Métriques du modèle DrepaViT\")\n",
    "    plt.ylim(0, 105); plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "# -----------------------\n",
    "# 3) Panneau (c) : Params & GFLOPs DrepaViT (2 barres)\n",
    "# -----------------------\n",
    "def panel_c(path=\"panel_c_params_gflops.png\", dpi=450):\n",
    "    plt.rcParams.update({\"font.size\": 11})\n",
    "    plt.figure(figsize=(7.2, 4.2))\n",
    "    labels = [\"Parameters (M)\", \"GFLOPs / image\"]\n",
    "    values = [drepavit[\"params\"]/1e6, drepavit[\"gflops\"]]\n",
    "    bars = plt.bar(labels, values, color=[\"#1f77b4\", \"#ff7f0e\"])\n",
    "\n",
    "    try:\n",
    "        plt.gca().bar_label(bars, labels=[f\"{values[0]:.2f}M\", f\"{values[1]:.3f}\"],\n",
    "                            label_type=\"edge\", padding=4, fontsize=10)\n",
    "    except Exception:\n",
    "        ymax = max(values) * 1.35\n",
    "        plt.ylim(0, ymax)\n",
    "        for r, txt in zip(bars, [f\"{values[0]:.2f}M\", f\"{values[1]:.3f}\"]):\n",
    "            h = r.get_height()\n",
    "            plt.text(r.get_x()+r.get_width()/2, h + 0.03*ymax, txt,\n",
    "                     ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"(c) DrepaViT — Parameters & GFLOPs @224×224\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "# -----------------------\n",
    "# 4) Génération des 3 panneaux\n",
    "# -----------------------\n",
    "a_path = panel_a()\n",
    "b_path = panel_b()\n",
    "c_path = panel_c()\n",
    "\n",
    "# -----------------------\n",
    "# 5) Fusion en figure composite (a/b/c)\n",
    "# -----------------------\n",
    "def fuse_horiz(images, out_png=\"fig_composite_abc.png\", out_pdf=\"fig_composite_abc.pdf\", gap=28, bg=\"white\"):\n",
    "    ims = [Image.open(p).convert(\"RGB\") for p in images]\n",
    "    H = max(im.height for im in ims)\n",
    "\n",
    "    # mettre toutes à la même hauteur (conservation des proportions)\n",
    "    resized = []\n",
    "    for im in ims:\n",
    "        if im.height != H:\n",
    "            new_w = int(im.width * (H / im.height))\n",
    "            im = im.resize((new_w, H), Image.LANCZOS)\n",
    "        resized.append(im)\n",
    "\n",
    "    total_w = sum(im.width for im in resized) + gap*(len(resized)-1)\n",
    "    canvas = Image.new(\"RGB\", (total_w, H), color=bg)\n",
    "\n",
    "    x = 0\n",
    "    for im in resized:\n",
    "        canvas.paste(im, (x, 0))\n",
    "        x += im.width + gap\n",
    "\n",
    "    canvas.save(out_png)\n",
    "    try:\n",
    "        canvas.save(out_pdf)  # PIL peut aussi exporter en PDF\n",
    "    except Exception:\n",
    "        pass\n",
    "    return out_png, out_pdf\n",
    "\n",
    "out_png, out_pdf = fuse_horiz([a_path, b_path, c_path],\n",
    "                              out_png=\"fig_drepavit_composite_abc.png\",\n",
    "                              out_pdf=\"fig_drepavit_composite_abc.pdf\")\n",
    "\n",
    "print(\"Composite saved:\", os.path.abspath(out_png), \"|\", os.path.abspath(out_pdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
